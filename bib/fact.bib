
@article{albertiSyntheticQACorpora2019,
  title = {Synthetic {{QA Corpora Generation}} with {{Roundtrip Consistency}}},
  author = {Alberti, Chris and Andor, Daniel and Pitler, Emily and Devlin, Jacob and Collins, Michael},
  year = {2019},
  month = jun,
  journal = {arXiv:1906.05416 [cs]},
  eprint = {1906.05416},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {We introduce a novel method of generating synthetic question answering corpora by combining models of question generation and answer extraction, and by filtering the results to ensure roundtrip consistency. By pretraining on the resulting corpora we obtain significant improvements on SQuAD2 and NQ, establishing a new state-of-the-art on the latter. Our synthetic data generation models, for both question generation and answer extraction, can be fully reproduced by finetuning a publicly available BERT model on the extractive subsets of SQuAD2 and NQ. We also describe a more powerful variant that does full sequence-to-sequence pretraining for question generation, obtaining exact match and F1 at less than 0.1\% and 0.4\% from human performance on SQuAD2.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Alberti et al_2019_Synthetic QA Corpora Generation with Roundtrip Consistency.pdf;/Users/mattshu/Zotero/storage/SYXJPGI2/1906.html}
}

@phdthesis{altinerIntegratingComputerbasedFlashcard2011,
  type = {Master of {{Science}}},
  title = {Integrating a Computer-Based Flashcard Program into Academic Vocabulary Learning},
  author = {Altiner, Cennet},
  year = {2011},
  address = {{Ames}},
  doi = {10.31274/etd-180810-375},
  abstract = {The main goal of this study is to investigate the extent to which a computer-based flashcard program, Anki, can help college-level ESL learners improve their vocabulary as well as the learners` perceptions about the program. The vocabulary targeted for the study consisted of Coxhead`s (2000) Academic Word List, including the most common words in university textbooks. An academic vocabulary dictionary which encompasses 210 academic words was designed for the study and thirteen students coming from two ESL classes used the Anki dictionary for ten minutes every day during the three week intervention process. Pretest and posttest scores of students were compared to evaluate the effectiveness of the learning process. Learners` perceptions about the training were investigated by means of surveys, interviews and observations. The results present the benefits that might be gained from the integration of flashcard programs into a language classroom, as well as the perceptions of learners about the process.},
  language = {en},
  school = {Iowa State University, Digital Repository},
  keywords = {_tablet,anki},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Altiner_2011_Integrating a computer-based flashcard program into academic vocabulary learning.pdf}
}

@article{alveroEssayContentStrongly,
  title = {Essay {{Content}} Is {{Strongly Related}} to {{Household Income}} and {{SAT Scores}}: {{Evidence}} from 60,000 {{Undergraduate Applications}}},
  author = {Alvero, AJ and Giebel, Sonia and {Gebre-Medhin}, Ben},
  pages = {26},
  abstract = {There is substantial evidence of the potential for class bias in the use of standardized tests to evaluate college applicants, yet little comparable inquiry considers the written essays typically required of applicants to selective US colleges and universities. We utilize a corpus of 240,000 admissions essays submitted by 60,000 applicants to the University of California in November 2016 to measure the relationship between the content of application essays, reported household income, and standardized test scores (SAT) at scale. We quantify essay content using correlated topic modeling (CTM) and the Linguistic Inquiry and Word Count (LIWC) software package. Results show that essays have a stronger correlation to reported household income than SAT scores. Essay content also explains much of the variance in SAT scores, suggesting that essays encode some of the same information as the SAT, though this relationship attenuates as household income increases. Efforts to realize more equitable college admissions protocols can be informed by attending to how social class is encoded in non-numerical components of applications.},
  language = {en},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Alvero et al_Essay Content is Strongly Related to Household Income and SAT Scores.pdf}
}

@article{andersonRetrievalinducedForgettingEvidence2000,
  title = {Retrieval-Induced Forgetting: {{Evidence}} for a Recall-Specific Mechanism},
  shorttitle = {Retrieval-Induced Forgetting},
  author = {Anderson, Michael C. and Bjork, Elizabeth L. and Bjork, Robert A.},
  year = {2000},
  month = sep,
  journal = {Psychon Bull Rev},
  volume = {7},
  number = {3},
  pages = {522--530},
  issn = {1531-5320},
  doi = {10.3758/BF03214366},
  abstract = {Previous work has shown that recalling information from long-term memory can impair the long-term retention of related representations\textemdash a phenomenon known as retrieval-induced forgetting (Anderson, Bjork, \& Bjork, 1994). We report an experiment in which the question of whether retrieval is necessary to induce this form of impairment was examined. All the subjects studied six members from each of eight taxonomic categories (e.g.,fruit orange). In the competitive practice condition, the subjects practiced recalling three of the six members, using category-stem cues (e.g.,fruit or\_\_\_\_). In the noncompetitive practice condition, the subjects were reexposed to these same members for the same number of repetitions but were asked to recall the category name by using the exemplar and a stem as cues (e.g.,fr\_\_\_\_orange). Despite significant and comparable facilitation of practiced items in both conditions, only the competitive practice subjects were impaired in their ability to recall the nonpracticed members on a delayed cued-recall test. These findings argue that retrieval-induced forgetting is not caused by increased competition arising from the strengthening of practiced items, but by inhibitory processes specific to the situation of recall.},
  language = {en},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Anderson et al_2000_Retrieval-induced forgetting.pdf}
}

@article{augustinHowLearnEffectively2014,
  title = {How to {{Learn Effectively}} in {{Medical School}}: {{Test Yourself}}, {{Learn Actively}}, and {{Repeat}} in {{Intervals}}},
  shorttitle = {How to {{Learn Effectively}} in {{Medical School}}},
  author = {Augustin, Marc},
  year = {2014},
  month = jun,
  journal = {Yale J Biol Med},
  volume = {87},
  number = {2},
  pages = {207--212},
  issn = {0044-0086},
  abstract = {Students in medical school often feel overwhelmed by the excessive amount of factual knowledge they are obliged to learn. Although a large body of research on effective learning methods is published, scientifically based learning strategies are not a standard part of the curriculum in medical school. Students are largely unaware of how to learn successfully and improve memory. This review outlines three fundamental methods that benefit learning: the testing effect, active recall, and spaced repetition. The review summarizes practical learning strategies to learn effectively and optimize long-term retention of factual knowledge.},
  pmcid = {PMC4031794},
  pmid = {24910566},
  keywords = {_tablet,to read},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Augustin_2014_How to Learn Effectively in Medical School.pdf}
}

@article{averellFormForgettingCurve2011,
  title = {The Form of the Forgetting Curve and the Fate of Memories},
  author = {Averell, Lee and Heathcote, Andrew},
  year = {2011},
  month = feb,
  journal = {Journal of Mathematical Psychology},
  series = {Special {{Issue}} on {{Hierarchical Bayesian Models}}},
  volume = {55},
  number = {1},
  pages = {25--35},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2010.08.009},
  abstract = {Psychologists have debated the form of the forgetting curve for over a century. We focus on resolving three problems that have blocked a clear answer on this issue. First, we analyzed data from a longitudinal experiment measuring cued recall and stem completion from 1 min to 28 days after study, with more observations per interval per participant than in previous studies. Second, we analyzed the data using hierarchical models, avoiding distortions due to averaging over participants. Third, we implemented the models in a Bayesian framework, enabling our analysis to account for the ability of candidate forgetting functions to imitate each other. An exponential function provided the best fit to individual participant data collected under both explicit and implicit retrieval instructions, but Bayesian model selection favored a power function. All analysis supported above chance asymptotic retention, suggesting that, despite quite brief study, storage of some memories was effectively permanent.},
  language = {en},
  keywords = {Bayesian model selection,Forgetting,Hierarchical models},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Averell_Heathcote_2011_The form of the forgetting curve and the fate of memories.pdf;/Users/mattshu/Zotero/storage/A3ML3C5D/S0022249610001100.html}
}

@article{bahrickImportanceRetrievalFailures2005,
  title = {The Importance of Retrieval Failures to Long-Term Retention: {{A}} Metacognitive Explanation of the Spacing Effect},
  shorttitle = {The Importance of Retrieval Failures to Long-Term Retention},
  author = {Bahrick, Harry P. and Hall, L. K.},
  year = {2005},
  doi = {10.1016/J.JML.2005.01.012},
  abstract = {Encoding strategies vary in their duration of effectiveness, and individuals can best identify and modify strategies that yield effects of short duration on the basis of retrieval failures. Multiple study sessions with long inter-session intervals are better than massed training at providing discriminative feedback that identifies encoding strategies of short duration. We report two investigations in which long intervals between study sessions yield substantial benefits to long-term retention, at a cost of only moderately longer individual study sessions. When individuals monitor and control encoding over an extended period, targets yielding the largest number of retrieval failures contribute substantially to the spacing advantage. These findings are relevant to theory and to educators whose primary interest in memory pertains to long-term maintenance of knowledge.}
}

@article{ballardObliviscenceReminiscence1913,
  title = {Obliviscence and {{Reminiscence}}},
  author = {Ballard, P.B.},
  year = {1913},
  journal = {British Journal of Psychology},
  volume = {1},
  number = {No. II},
  pages = {82--82},
  publisher = {{British Psychological Society}},
  address = {{United Kingdom}},
  issn = {2044-8295(Electronic),0007-1269(Print)},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Ballard_1913_Obliviscence and Reminiscence.pdf;/Users/mattshu/Zotero/storage/56K4L3E5/1913-10033-001.html}
}

@article{bengioRepresentationLearningReview2013,
  title = {Representation {{Learning}}: {{A Review}} and {{New Perspectives}}},
  shorttitle = {Representation {{Learning}}},
  author = {Bengio, Y. and Courville, A. and Vincent, P.},
  year = {2013},
  month = aug,
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {35},
  number = {8},
  pages = {1798--1828},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2013.50},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Bengio et al_2013_Representation Learning.pdf}
}

@article{bianchiPretrainingHotTopic2020,
  title = {Pre-Training Is a {{Hot Topic}}: {{Contextualized Document Embeddings Improve Topic Coherence}}},
  shorttitle = {Pre-Training Is a {{Hot Topic}}},
  author = {Bianchi, Federico and Terragni, Silvia and Hovy, Dirk},
  year = {2020},
  month = apr,
  journal = {arXiv:2004.03974 [cs]},
  eprint = {2004.03974},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Topic models extract meaningful groups of words from documents, allowing for a better understanding of data. However, the solutions are often not coherent enough, and thus harder to interpret. Coherence can be improved by adding more contextual knowledge to the model. Recently, neural topic models have become available, while BERT-based representations have further pushed the state of the art of neural models in general. We combine pre-trained representations and neural topic models. Pre-trained BERT sentence embeddings indeed support the generation of more meaningful and coherent topics than either standard LDA or existing neural topic models. Results on four datasets show that our approach effectively increases topic coherence.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Bianchi et al_2020_Pre-training is a Hot Topic.pdf;/Users/mattshu/Zotero/storage/WAHXRYCS/2004.html}
}

@misc{bienstmanMnemosyneProject2020,
  title = {The Mnemosyne Project},
  author = {Bienstman, Peter},
  year = {2020},
  howpublished = {https://mnemosyne-proj.org/},
  file = {/Users/mattshu/Zotero/storage/3SF3RYAB/mnemosyne-proj.org.html}
}

@article{bowerRelationshipUseSpaced2016,
  title = {The {{Relationship}} between the {{Use}} of {{Spaced Repetition Software}} with a {{TOEIC Word List}} and {{TOEIC Score Gains}}},
  author = {Bower, Jack Victor and {Rutson-Griffiths}, Arthur},
  year = {2016},
  journal = {Computer Assisted Language Learning},
  volume = {29},
  number = {7},
  pages = {1238--1248},
  issn = {0958-8221},
  doi = {10.1080/09588221.2016.1222444},
  abstract = {A strong relationship between L2 vocabulary knowledge and L2 reading and listening comprehension is well established. However, less research has been conducted to explore correlations between pedagogic interventions to increase vocabulary knowledge and score gains on standardized L2 proficiency tests. This study addresses this gap in the research by analyzing the relationship between extended study of a Test of English for International Communication (TOEIC) word list using spaced repetition software (SRS) and TOEIC score gains. Two classes of Japanese students totaling 60 participants were encouraged to study a TOEIC word list using SRS for 10 months. TOEIC score gains from a pre-test to a post-test were then correlated with the number of flashcard repetitions to investigate the relationship between SRS study and test score gains. Statistically significant relationships (p {$<$} 0.05) were found between total SRS repetitions and TOEIC listening and overall score gains. Total word list reviews accounted for 11.4\% of the variance in overall TOEIC gains, 6.2\% of the variance in reading gain and 7.2\% of the variance in listening gains. The authors argue that study of test-specific word lists with SRS may be a useful addition to motivated students' test preparation strategies for standardized foreign language proficiency tests.},
  language = {en},
  keywords = {Achievement Gains,Asians,College Students,Computer Software,Correlation,English (Second Language),Females,Foreign Countries,Instructional Materials,Intervention,Language Proficiency,Language Tests,Listening Comprehension,Pretests Posttests,Reading Comprehension,Scores,Second Language Instruction,Second Language Learning,Single Sex Colleges,spaced-repetition,Standardized Tests,Statistical Analysis,Teaching Methods,Test Preparation,Translation,Vocabulary Development,Word Lists},
  file = {/Users/mattshu/Zotero/storage/ZBLEL3TS/eric.ed.gov.html}
}

@misc{branwenSpacedRepetitionEfficient2009,
  title = {Spaced {{Repetition}} for {{Efficient Learning}} - {{Gwern}}.Net},
  author = {Branwen, Gwern},
  year = {2009},
  month = mar,
  abstract = {Efficient memorization using the spacing effect: literature review of widespread applicability, tips on use \& what it's good for.},
  copyright = {https://creativecommons.org/publicdomain/zero/1.0/},
  howpublished = {https://www.gwern.net/Spaced-repetition},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/GLVCMT5J/Spaced-repetition.html}
}

@misc{bushWeMayThink1945,
  title = {As {{We May Think}}},
  author = {Bush, Vannevar},
  year = {1945},
  month = jul,
  journal = {The Atlantic},
  abstract = {``Consider a future device \ldots ~~in which an individual stores all his books, records, and communications, and which is mechanized so that it may be consulted with exceeding speed and flexibility. It is an enlarged intimate supplement to his memory.''},
  chapter = {Technology},
  howpublished = {https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/},
  language = {en-US},
  file = {/Users/mattshu/Zotero/storage/KWEJJKJG/303881.html}
}

@article{carvalhoBenefitsInterleavedBlocked2015,
  title = {The Benefits of Interleaved and Blocked Study: {{Different}} Tasks Benefit from Different Schedules of Study},
  shorttitle = {The Benefits of Interleaved and Blocked Study},
  author = {Carvalho, Paulo F. and Goldstone, Robert L.},
  year = {2015},
  month = feb,
  journal = {Psychon Bull Rev},
  volume = {22},
  number = {1},
  pages = {281--288},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-014-0676-4},
  abstract = {Research on how information should be studied during inductive category learning has identified both interleaving of categories and blocking by category as beneficial for learning. Previous work suggests that this mixed evidence can be reconciled by taking into account within- and betweencategory similarity relations. In this article, we present a new moderating factor. Across two experiments, one group of participants studied categories actively (by studying the objects without correct category assignment and actively figuring out what the category was), either interleaved or blocked. Another group studied the same categories passively (objects and correct category assignment were simultaneously provided). Results from a subsequent generalization task show that whether interleaved or blocked study results in better learning depends on whether study is active or passive. One account of these results is that different presentation sequences and tasks promote different patterns of attention to stimulus components. Passive learning and blocking promote attending to commonalities within categories, while active learning and interleaving promote attending to differences between categories.},
  language = {en},
  keywords = {_tablet,to read},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Carvalho_Goldstone_2015_The benefits of interleaved and blocked study.pdf}
}

@article{carvalhoPuttingCategoryLearning2014,
  title = {Putting Category Learning in Order: {{Category}} Structure and Temporal Arrangement Affect the Benefit of Interleaved over Blocked Study},
  shorttitle = {Putting Category Learning in Order},
  author = {Carvalho, Paulo F. and Goldstone, Robert L.},
  year = {2014},
  month = apr,
  journal = {Mem Cogn},
  volume = {42},
  number = {3},
  pages = {481--495},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/s13421-013-0371-0},
  abstract = {Recent research in inductive category learning has demonstrated that interleaved study of category exemplars results in better performance than does studying each category in separate blocks. However, the questions of how the category structure influences this advantage and how simultaneous presentation interacts with the advantage are open issues. In this article, we present three experiments. The first experiment indicates that the advantage of interleaved over blocked study is modulated by the structure of the categories being studied. More specifically, interleaved study results in better generalization for categories with high within- and between-category similarity, whereas blocked presentation results in better generalization for categories with low within- and between-category similarity. In Experiment 2, we present evidence that when presented simultaneously, between-category comparisons (interleaved presentation) result in a performance advantage for high-similarity categories, but no differences were found for low-similarity categories. In Experiment 3, we directly compared simultaneous and successive presentation of low-similarity categories. We again found an overall benefit for blocked study with these categories. Overall, these results are consistent with the proposal that interleaving emphasizes differences between categories, whereas blocking emphasizes the discovery of commonalities among objects within the same category.},
  language = {en},
  keywords = {_tablet,to read},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Carvalho_Goldstone_2014_Putting category learning in order.pdf}
}

@article{chanRetrievalinducedFacilitationInitially2006,
  title = {Retrieval-Induced Facilitation: {{Initially}} Nontested Material Can Benefit from Prior Testing of Related Material},
  shorttitle = {Retrieval-Induced Facilitation},
  author = {Chan, Jason C. K. and McDermott, Kathleen B. and Roediger, Henry L.},
  year = {2006},
  journal = {Journal of Experimental Psychology: General},
  volume = {135},
  number = {4},
  pages = {553--571},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-2222(Electronic),0096-3445(Print)},
  doi = {10.1037/0096-3445.135.4.553},
  abstract = {Classroom exams can assess students' knowledge of only a subset of the material taught in a course. What are the implications of this approach for long-term retention? Three experiments (N = 210) examined how taking an initial test affects later memory for prose materials not initially tested. Experiment 1 shows that testing enhanced recall 24 hr later for the initially nontested material. This facilitation was not seen for participants given additional study opportunities without initial testing. Experiment 2 extends this facilitative effect to a within-subjects design. Experiment 3 demonstrates that this facilitation can be modulated by conscious strategies. These results have implications for educational practice and the theoretical developments of the testing effect, associative memory, and retrieval inhibition. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Latent Inhibition,Memory,Recall (Learning),Retention,Semantic Priming,Test Taking},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Chan et al_2006_Retrieval-induced facilitation.pdf;/Users/mattshu/Zotero/storage/X8ZKRUL6/2006-20327-005.html}
}

@article{chanWhenDoesRetrieval2009,
  title = {When Does Retrieval Induce Forgetting and When Does It Induce Facilitation? {{Implications}} for Retrieval Inhibition, Testing Effect, and Text Processing},
  shorttitle = {When Does Retrieval Induce Forgetting and When Does It Induce Facilitation?},
  author = {Chan, Jason C.K.},
  year = {2009},
  month = aug,
  journal = {Journal of Memory and Language},
  volume = {61},
  number = {2},
  pages = {153--170},
  issn = {0749596X},
  doi = {10.1016/j.jml.2009.04.004},
  abstract = {Retrieval practice can enhance long-term retention of the tested material (the testing effect), but it can also impair later recall of the nontested material \textendash{} a phenomenon known as retrieval-induced forgetting (Anderson, M. C., Bjork, R. A., \& Bjork, E. L. (1994). Remembering can cause forgetting: retrieval dynamics in long-term memory. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20(5), 1063\textendash 1087). Recent research, however, has shown that retrieval practice can sometimes improve later recall of the nontested material \textendash{} a phenomenon termed retrieval-induced facilitation (Chan, J. C. K., McDermott, K. B., \& Roediger, H. L. (2006). Retrieval-induced facilitation: initially nontested material can benefit from prior testing of related material. Journal of Experimental Psychology: General, 135, 553\textendash 571). What drives these different effects? Two experiments were designed to examine the conditions under which retrieval induces forgetting and facilitation. Two variables, the level of integration invoked during encoding and the length of delay between retrieval practice and final test, were revealed as critical factors in determining whether testing facilitated or hindered later retrieval of the nontested information. A text processing framework is advanced to account for these findings.},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/83LK46AZ/Chan - 2009 - When does retrieval induce forgetting and when doe.pdf}
}

@article{choiDecontextualizationMakingSentences2021,
  title = {Decontextualization: {{Making Sentences Stand}}-{{Alone}}},
  shorttitle = {Decontextualization},
  author = {Choi, Eunsol and Palomaki, Jennimaria and Lamm, Matthew and Kwiatkowski, Tom and Das, Dipanjan and Collins, Michael},
  year = {2021},
  month = feb,
  journal = {arXiv:2102.05169 [cs]},
  eprint = {2102.05169},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Models for question answering, dialogue agents, and summarization often interpret the meaning of a sentence in a rich context and use that meaning in a new context. Taking excerpts of text can be problematic, as key pieces may not be explicit in a local window. We isolate and define the problem of sentence decontextualization: taking a sentence together with its context and rewriting it to be interpretable out of context, while preserving its meaning. We describe an annotation procedure, collect data on the Wikipedia corpus, and use the data to train models to automatically decontextualize sentences. We present preliminary studies that show the value of sentence decontextualization in a user facing task, and as preprocessing for systems that perform document understanding. We argue that decontextualization is an important subtask in many downstream applications, and that the definitions and resources provided can benefit tasks that operate on sentences that occur in a richer context.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Choi et al_2021_Decontextualization.pdf;/Users/mattshu/Zotero/storage/Q6VW232G/2102.html}
}

@article{cohenStudentsThinkThat2013,
  title = {Do Students Think That Difficult or Valuable Materials Should Be Restudied Sooner Rather than Later?},
  author = {Cohen, Michael S. and Yan, Veronica X. and Halamish, Vered and Bjork, Robert A.},
  year = {2013},
  month = nov,
  journal = {J Exp Psychol Learn Mem Cogn},
  volume = {39},
  number = {6},
  pages = {1682--1696},
  issn = {1939-1285},
  doi = {10.1037/a0032425},
  abstract = {Despite the clear long-term benefits of spaced practice, students and teachers often choose massed practice. Whether learners actually fail to appreciate the benefits of spacing is, however, open to question. Early studies (e.g., Zechmeister \& Shaughnessy, 1980) found that participants' judgments of learning were higher after massed than after spaced repetitions, but more recent studies have found that participants, when allowed to choose between restudying right away and restudying later, tend to choose later, apparently reflecting an appreciation for the benefits of spacing. In these recent studies, however, choosing to restudy later also meant restudying closer to the final test, leaving open the question of what was driving participants' choices. In addition, the choice confronting participants has typically been between getting a spaced and truly massed repetition, whereas in real-world learning contexts the choice is often between a short, but not immediate, spacing interval and a longer one. In our research, we controlled final retention interval and asked participants to choose between restudying word pairs after either a relatively short (but not truly massed) interval or a longer interval. We found that participants had a clear preference for restudying higher priority (more difficult or more valuable) items sooner rather than later, even when doing so was not the most effective option. Thus, previous findings showing a preference for spaced repetition do not extend to a context in which the shorter spacing interval is substantially longer than true massing, and they may merely reflect a preference to restudy closer to the test.},
  language = {eng},
  pmid = {23565792},
  keywords = {Adult,Association Learning,Humans,Learning,Mental Recall,Students,Time Factors,Word Association Tests,Young Adult},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Cohen et al_2013_Do students think that difficult or valuable materials should be restudied.pdf}
}

@article{devlinBERTPretrainingDeep2018,
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2018},
  month = oct,
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.   BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Devlin et al_2018_BERT.pdf;/Users/mattshu/Zotero/storage/RTFKHKNB/1810.html}
}

@article{diekelmannMemoryFunctionSleep2010,
  title = {The Memory Function of Sleep},
  author = {Diekelmann, Susanne and Born, Jan},
  year = {2010},
  month = feb,
  journal = {Nature Reviews Neuroscience},
  volume = {11},
  number = {2},
  pages = {114--126},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn2762},
  abstract = {Sleep promotes the consolidation of declarative as well as procedural and emotional memories in a wide variety of tasks. Sleep improves preferentially the consolidation of memories that were encoded explicitly and are behaviourally relevant to the individual.Consolidation during sleep not only strengthens memory traces quantitatively but can also produce qualitative changes in memory representations. An active process of re-organization enables the formation of new associations and the extraction of generalized features. This can ease novel inferences and insights.Spatio-temporal patterns of neuronal activity during encoding in the awake state become re-activated during subsequent sleep, specifically during slow-wave sleep (SWS) which is a state of minimum cholinergic activity. Such re-activations might promote the gradual redistribution of hippocampus-dependent memories from the hippocampus to neocortical sites for long-term storage (system consolidation) and might also trigger enduring synaptic changes to stabilize memories (synaptic consolidation).Neocortical ({$<$}1 Hz) slow oscillations, thalamo-cortical spindles and hippocampal sharp-wave ripples are implicated in memory consolidation during SWS. The depolarizing up-states of the slow oscillations synchronously drive the generation of spindles and ripples accompanying hippocampal memory re-activations, thus providing a temporal frame for a fine-tuned hippocampus-to-neocortex transfer of memories.Neocortical slow oscillations concurrently support a global synaptic downscaling that precludes saturation of synaptic networks and improves the capacity to encode new information.Rapid eye movement (REM) sleep is characterized by a local upregulation of plasticity-related immediate early genes in the presence of high cholinergic activity and reduced electroencephalographic coherence between brain regions. These conditions might effectively support local synaptic consolidation.The temporal sequence of SWS and REM sleep in the normal sleep cycle suggests that these sleep stages have complementary roles in memory consolidation: during SWS, system consolidation promotes the re-activation and redistribution of select memory traces for long-term storage, whereas ensuing REM sleep might act to stabilize the transformed memories by enabling undisturbed synaptic consolidation.},
  copyright = {2010 Nature Publishing Group},
  language = {en},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Diekelmann_Born_2010_The memory function of sleep.pdf;/Users/mattshu/Zotero/storage/PI8LX8IT/nrn2762.html}
}

@inproceedings{donoghueMetaAnalysisTenLearning2021,
  title = {A {{Meta}}-{{Analysis}} of {{Ten Learning Techniques}}},
  booktitle = {Frontiers in {{Education}}},
  author = {Donoghue, Gregory M. and Hattie, J.},
  year = {2021},
  doi = {10.3389/feduc.2021.581216},
  abstract = {This article outlines a meta-analysis of the 10 learning techniques identified in Dunlosky et al. (2013a), and is based on 242 studies, 1,619 effects, 169,179 unique participants, with an overall mean of 0.56. The most effective techniques are Distributed Practice and Practice Testing and the least effective (but still with relatively high effects) are Underlining and Summarization. A major limitation was that the majority of studies in the meta-analysis were based on surface or factual outcomes, and there is caution needed when applying these findings to deeper and more relational outcomes. Other important moderators included the presence of feedback or not, near or far transfer, and the effects were much greater for lower than higher ability students. It is recommended that more attention be paid to when, under what conditions, each technique can be used, and how they can best be taught.},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Donoghue_Hattie_2021_A Meta-Analysis of Ten Learning Techniques.pdf}
}

@inproceedings{donovanMetaanalyticReviewDistribution1999,
  title = {A Meta-Analytic Review of the Distribution of Practice Effect: {{Now}} You See It, Now You Don't.},
  shorttitle = {A Meta-Analytic Review of the Distribution of Practice Effect},
  author = {Donovan, J. and Radosevich, David J.},
  year = {1999},
  doi = {10.1037/0021-9010.84.5.795},
  abstract = {The present review examined the relationship between conditions of massed practice and spaced practice with respect to task performance. A meta-analysis of 63 studies with 112 effect sizes yielded an overall mean weighted effect size of 0.46, indicating that individuals in spaced practice conditions performed significantly higher than those in massed practice conditions. Subsequent analyses, however, suggested that the nature of the task- being practiced, the intertrial time interval, and the interaction between these two variables significantly moderated the relationship between practice conditions and performance. In addition,, significantly higher effect sizes were found in studies with low methodological rigor as compared with those studies higher in rigor. Directions for future research and applications of the findings are discussed.},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Donovan_Radosevich_1999_A meta-analytic review of the distribution of practice effect.pdf}
}

@article{dudaiNeurobiologyConsolidationsHow2004,
  title = {The Neurobiology of Consolidations, or, How Stable Is the Engram?},
  author = {Dudai, Yadin},
  year = {2004},
  journal = {Annu Rev Psychol},
  volume = {55},
  pages = {51--86},
  issn = {0066-4308},
  doi = {10.1146/annurev.psych.55.090902.142050},
  abstract = {Consolidation is the progressive postacquisition stabilization of long-term memory. The term is commonly used to refer to two types of processes: synaptic consolidation, which is accomplished within the first minutes to hours after learning and occurs in all memory systems studied so far; and system consolidation, which takes much longer, and in which memories that are initially dependent upon the hippocampus undergo reorganization and may become hippocampal-independent. The textbook account of consolidation is that for any item in memory, consolidation starts and ends just once. Recently, a heated debate has been revitalized on whether this is indeed the case, or, alternatively, whether memories become labile and must undergo some form of renewed consolidation every time they are activated. This debate focuses attention on fundamental issues concerning the nature of the memory trace, its maturation, persistence, retrievability, and modifiability.},
  language = {eng},
  pmid = {14744210},
  keywords = {Humans,Memory,Neurobiology,Neurons,Signal Transduction,Synapses},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Dudai_2004_The neurobiology of consolidations, or, how stable is the engram.pdf}
}

@article{dunloskyImprovingStudentsLearning2013,
  title = {Improving {{Students}}' {{Learning With Effective Learning Techniques}}: {{Promising Directions From Cognitive}} and {{Educational Psychology}}},
  shorttitle = {Improving {{Students}}' {{Learning With Effective Learning Techniques}}},
  author = {Dunlosky, John and Rawson, Katherine A. and Marsh, Elizabeth J. and Nathan, Mitchell J. and Willingham, Daniel T.},
  year = {2013},
  month = jan,
  journal = {Psychol Sci Public Interest},
  volume = {14},
  number = {1},
  pages = {4--58},
  issn = {1529-1006, 1539-6053},
  doi = {10.1177/1529100612453266},
  abstract = {Many students are being left behind by an educational system that some people believe is in crisis. Improving educational outcomes will require efforts on many fronts, but a central premise of this monograph is that one part of a solution involves helping students to better regulate their learning through the use of effective learning techniques. Fortunately, cognitive and educational psychologists have been developing and evaluating easy-to-use learning techniques that could help students achieve their learning goals. In this monograph, we discuss 10 learning techniques in detail and offer recommendations about their relative utility. We selected techniques that were expected to be relatively easy to use and hence could be adopted by many students. Also, some techniques (e.g., highlighting and rereading) were selected because students report relying heavily on them, which makes it especially important to examine how well they work. The techniques include elaborative interrogation, self-explanation, summarization, highlighting (or underlining), the keyword mnemonic, imagery use for text learning, rereading, practice testing, distributed practice, and interleaved practice.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Dunlosky et al_2013_Improving Studentsâ€™ Learning With Effective Learning Techniques.pdf}
}

@misc{DuolingoWorldBest,
  title = {Duolingo - {{The}} World's Best Way to Learn a Language},
  journal = {Duolingo},
  abstract = {With our free mobile app or web and a few minutes a day, everyone can Duolingo. Learn 30+ languages online with bite-size lessons based on science.},
  howpublished = {https://www.duolingo.com/},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/X5WKP4IN/www.duolingo.com.html}
}

@book{ebbinghausMemoryContributionExperimental1913,
  title = {Memory: {{A}} Contribution to Experimental Psychology.},
  shorttitle = {Memory},
  author = {Ebbinghaus, Hermann},
  translator = {Ruger, Henry A. and Bussenius, Clara E.},
  year = {1913},
  publisher = {{Teachers College Press}},
  address = {{New York}},
  doi = {10.1037/10011-000},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Ebbinghaus_1913_Memory.pdf}
}

@article{edgeMemReflexAdaptiveFlashcards,
  title = {{{MemReflex}}: {{Adaptive Flashcards}} for {{Mobile Microlearning}}},
  author = {Edge, Darren},
  pages = {10},
  abstract = {Flashcard systems typically help students learn facts (e.g., definitions, names, and dates), relying on intense initial memoriztion with subsequent tests delayed up to days later. This approach does not exploit the short, sparse, and mobile opportunities for microlearning throughout the day, nor does it support learners who need the motivation that comes from successful study sessions. In contrast, our MemReflex system of adaptive flashcards gives fast-feedback by retesting new items in quick succession, dynamically scheduling future tests according to a model of the learner's memory. We evaluate MemReflex across three user studies. In the first two studies, we demonstrate its effectiveness for both audio and text modalities, even while walking and distracted. In the third study of second-language vocabulary learning, we show how MemReflex enhanced learner accuracy, confidence, and perceptions of control and success. Overall, the work suggests new directions for mobile microlearning and ``micro activities'' in general.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Edge_MemReflex.pdf}
}

@inproceedings{edgeMicroMandarinMobileLanguage2011,
  title = {{{MicroMandarin}}: Mobile Language Learning in Context},
  shorttitle = {{{MicroMandarin}}},
  booktitle = {Proceedings of the 2011 Annual Conference on {{Human}} Factors in Computing Systems - {{CHI}} '11},
  author = {Edge, Darren and Searle, Elly and Chiu, Kevin and Zhao, Jing and Landay, James A.},
  year = {2011},
  pages = {3169},
  publisher = {{ACM Press}},
  address = {{Vancouver, BC, Canada}},
  doi = {10.1145/1978942.1979413},
  abstract = {Learning a new language is hard, but learning to use it confidently in conversations with native speakers is even harder. From our field research with language learners, with support from Cognitive Psychology and Second Language Acquisition, we argue for the value of contextual microlearning in the many breaks spread across different places and throughout the day. We present a mobile application that supports such microlearning by leveraging the location-based service Foursquare to automatically provide contextually relevant content in the world's major cities. In an evaluation of Mandarin Chinese learning, a four-week, 23-user study spanning Beijing and Shanghai compared this contextual system to a system based on word frequency. Study sessions with the contextual version lasted half as long but occurred in twice as many places as sessions with the frequency version, suggesting a complementary relationship between the two approaches.},
  isbn = {978-1-4503-0228-9},
  language = {en}
}

@misc{elmesAnkiManual2021,
  title = {Anki {{Manual}}},
  author = {Elmes, Damien},
  year = {2021},
  month = jan,
  howpublished = {https://docs.ankiweb.net/},
  file = {/Users/mattshu/Zotero/storage/MQJ8XSKJ/docs.ankiweb.net.html}
}

@misc{elmesAnkiPowerfulIntelligent2021,
  title = {Anki - Powerful, Intelligent Flashcards},
  author = {Elmes, Damien},
  year = {2021},
  howpublished = {https://apps.ankiweb.net/},
  file = {/Users/mattshu/Zotero/storage/WP4PFEWS/apps.ankiweb.net.html}
}

@article{erdelyiHasEbbinghausDecayed1978,
  title = {Has {{Ebbinghaus}} Decayed with Time? {{The}} Growth of Recall (Hypermnesia) over Days},
  shorttitle = {Has {{Ebbinghaus}} Decayed with Time?},
  author = {Erdelyi, Matthew Hugh and Kleinbard, Jeff},
  year = {1978},
  journal = {Journal of Experimental Psychology: Human Learning and Memory},
  volume = {4},
  number = {4},
  pages = {275--289},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {0096-1515(Print)},
  doi = {10.1037/0278-7393.4.4.275},
  abstract = {Experimental research on memory since H. Ebbinghaus has predominantly focused on the fact of forgetting, creating the impression that memory inevitably decreases with time or time-correlated interpolated events. Recent laboratory work on the recall of pictures, however, has suggested that memory for certain classes of stimuli may be hypermnesic rather than amnesic, increasing over time and recall attempts. The present study attempted to determine the magnitude of memory growth over more significant time intervals. Tests of memory up to 1 wk, in 1 and 6 Ss, indicated substantial growth of recall for pictures, but not usually for words. The outcomes are discussed in terms of (a) their bearing on the Ebbinghaus experimental tradition; (b) the relation of this study to other hypermnesia literature, including P. B. Ballard's reminiscence, hypnotic hypermnesia, memory recoveries in therapy, and the Penfield effect; and (c) the implications of hypermnesia for psychodynamics and unconscious processes. (41 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Forgetting,Human Information Storage,Memory,Pictorial Stimuli,Recall (Learning),Retention,Words (Phonetic Units)},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Erdelyi_Kleinbard_1978_Has Ebbinghaus decayed with time.pdf;/Users/mattshu/Zotero/storage/YPXFS6VU/1979-20297-001.html}
}

@article{erdelyiHypermnesiaPicturesIncremental1974,
  title = {Hypermnesia for Pictures: {{Incremental}} Memory for Pictures but Not Words in Multiple Recall Trials},
  shorttitle = {Hypermnesia for Pictures},
  author = {Erdelyi, Matthew Hugh and Becker, Joan},
  year = {1974},
  month = jan,
  journal = {Cognitive Psychology},
  volume = {6},
  number = {1},
  pages = {159--171},
  issn = {0010-0285},
  doi = {10.1016/0010-0285(74)90008-5},
  abstract = {Two studies are reported on multiple forced recall following a single visual presentation of a sequence of pictures or words. In both experiments, a hypermnesic memory function (in which performance improved with repeated recall) was obtained for pictures, while a flat, nonincremental function was obtained for words. Interpolation of intervals of thinking between recall trials further enhanced hypermnesia for pictorial items. Retrieval, whether overt (recall trials) or covert (thinking), apparently produces increased net recovery of pictures but not words.},
  language = {en},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Erdelyi_Becker_1974_Hypermnesia for pictures.pdf}
}

@article{erdelyiUpsDownsMemory2010,
  title = {The Ups and Downs of Memory},
  author = {Erdelyi, Matthew Hugh},
  year = {2010},
  journal = {American Psychologist},
  volume = {65},
  number = {7},
  pages = {623--633},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1935-990X(Electronic),0003-066X(Print)},
  doi = {10.1037/a0020440},
  abstract = {Ever since the classic work of Ebbinghaus (1885/1964), the default view in scientific psychology has been that memory declines over time. Less well-known clinical and laboratory traditions suggest, however, that memory can also increase over time. Ballard (1913) demonstrated that, actually, memory simultaneously increases and decreases over time and thus has not 1 but 2 tendencies. When more than 1 recall test is administered, a later test invariably shows loss of some items remembered earlier (oblivescence), but later tests also invariably show that previously unremembered items are recovered in later tests (reminiscence). Depending on a number of factors (e.g., the stimulus used), the overall balance between reminiscence and oblivescence may be positive (hypermnesia) or negative (amnesia). Modern multitrial recall studies have extensively documented hypermnesic memory in single laboratory sessions and, also, although less frequently, over periods of days, weeks, and even months. With hypermnesic memory now established, hypnosis has been shown not to add anything to regular hypermnesia. This article presents an integration of the scattered literatures, which now, after a century of experimental and clinical effort, coheres into a solid empirical picture, with numerous implications (e.g., for the recovered memory controversy, eyewitness testimony, repression, and subliminal perception). (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Amnesia,Forgetting,Reminiscence,Retention},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Erdelyi_2010_The ups and downs of memory.pdf;/Users/mattshu/Zotero/storage/Z7DIY9WR/2010-19922-001.html}
}

@misc{eshapardAnkiStartingEase,
  title = {Anki's {{Starting Ease Factor Setting}}},
  author = {{eshapard}},
  abstract = {In a Nutshell For each deck options group in Anki, set the initial ease factor to the average ease factor of the mature cards in that deck options group. UPDATE 2017-02-15: I completed an addon to do this automatically for all decks. To install from within Anki, use Tools~\guillemotright{} Addons~\guillemotright...},
  howpublished = {http://eshapard.github.io/anki/ankis-initial-ease-factor-setting.html},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/3QITQEE8/ankis-initial-ease-factor-setting.html}
}

@misc{fasihFasihaEbisu2020,
  title = {Fasiha/Ebisu},
  author = {Fasih, Ahmed},
  year = {2020},
  month = dec,
  abstract = {Public-domain Python library for quiz scheduling using Bayesian statistics. (Also available as JavaScript and Java ports!)},
  copyright = {Unlicense License         ,                 Unlicense License},
  keywords = {bayesian-statistics,monte-carlo,probability-density,python,python3,quiz,recall,recall-probabilities,review,spaced-repetition,statistical-methods},
  file = {/Users/mattshu/Zotero/storage/DFMJE3ZV/Edge et al. - 2011 - MicroMandarin mobile language learning in context.pdf}
}

@book{gentnerMentalModels2014,
  title = {Mental {{Models}}},
  author = {Gentner, Dedre and Stevens, Albert L.},
  year = {2014},
  month = jan,
  publisher = {{Psychology Press}},
  abstract = {This classic volume compiles and describes interdisciplinary research on the formal nature of human knowledge about the world. Three key dimensions that characterize mental models research are examined: the nature of the domain studied, the nature of the theoretical approach, and the nature of the methodology.},
  googlebooks = {G8iYAgAAQBAJ},
  isbn = {978-1-317-76940-8},
  language = {en},
  keywords = {Psychology / General,Psychology / Research \& Methodology}
}

@article{goldstoneIsolatedInterrelatedConcepts1996,
  title = {Isolated and Interrelated Concepts},
  author = {Goldstone, Robert L.},
  year = {1996},
  month = sep,
  journal = {Mem Cogn},
  volume = {24},
  number = {5},
  pages = {608--628},
  issn = {1532-5946},
  doi = {10.3758/BF03201087},
  abstract = {A continuum between purely isolated and purely interrelated concepts is described. Along this continuum, a concept is interrelated to the extent that it is influenced by other concepts. Methods for manipulating and identifying a concept's degree of interrelatedness are introduced. Relatively isolated concepts can be empirically identified by a relatively large use of nondiagnostic features, and by better categorization performance for a concept's prototype than for a caricature of the concept. Relatively interrelated concepts can be identified by minimal use of nondiagnostic features, and by better categorization performance for a caricature than for a prototype. A concept is likely to be relatively isolated when subjects are instructed to create images for their concepts rather than find discriminating features, when concepts are given unrelated labels, and when the categories that are displayed alternate rarely between trials. The entire set of manipulations and measurements supports a graded distinction between isolated and interrelated concepts. The distinction is applied to current models of category learning, and a connectionist framework for interpreting the empirical results is presented.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Goldstone_1996_Isolated and interrelated concepts.pdf}
}

@misc{gunterStudentRecruitment,
  title = {Student {{Recruitment}}},
  author = {Gunter, Emily},
  journal = {Partnership for Academic Competition Excellence},
  abstract = {Home of the National Scholastic Championship},
  howpublished = {http://www.pace-nsc.org/},
  language = {en-US},
  file = {/Users/mattshu/Zotero/storage/RTLCAVIR/student-recruitment.html}
}

@article{guoCalibrationModernNeural2017,
  title = {On {{Calibration}} of {{Modern Neural Networks}}},
  author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
  year = {2017},
  month = aug,
  journal = {arXiv:1706.04599 [cs]},
  eprint = {1706.04599},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Confidence calibration -- the problem of predicting probability estimates representative of the true correctness likelihood -- is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling -- a single-parameter variant of Platt Scaling -- is surprisingly effective at calibrating predictions.},
  archiveprefix = {arXiv},
  keywords = {_tablet,Computer Science - Machine Learning},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Guo et al_2017_On Calibration of Modern Neural Networks.pdf;/Users/mattshu/Zotero/storage/Y6Q5XHV3/1706.html}
}

@article{hunzikerTeachingMultipleConcepts2019,
  title = {Teaching {{Multiple Concepts}} to a {{Forgetful Learner}}},
  author = {Hunziker, Anette and Chen, Yuxin and Mac Aodha, Oisin and Rodriguez, Manuel Gomez and Krause, Andreas and Perona, Pietro and Yue, Yisong and Singla, Adish},
  year = {2019},
  month = oct,
  journal = {arXiv:1805.08322 [cs]},
  eprint = {1805.08322},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {How can we help a forgetful learner learn multiple concepts within a limited time frame? While there have been extensive studies in designing optimal schedules for teaching a single concept given a learner's memory model, existing approaches for teaching multiple concepts are typically based on heuristic scheduling techniques without theoretical guarantees. In this paper, we look at the problem from the perspective of discrete optimization and introduce a novel algorithmic framework for teaching multiple concepts with strong performance guarantees. Our framework is both generic, allowing the design of teaching schedules for different memory models, and also interactive, allowing the teacher to adapt the schedule to the underlying forgetting mechanisms of the learner. Furthermore, for a well-known memory model, we are able to identify a regime of model parameters where our framework is guaranteed to achieve high performance. We perform extensive evaluations using simulations along with real user studies in two concrete applications: (i) an educational app for online vocabulary teaching; and (ii) an app for teaching novices how to recognize animal species from images. Our results demonstrate the effectiveness of our algorithm compared to popular heuristic approaches.},
  archiveprefix = {arXiv},
  language = {en},
  keywords = {_tablet,Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Hunziker et al_2019_Teaching Multiple Concepts to a Forgetful Learner.pdf}
}

@misc{jacksonFlashcardsQBWiki,
  title = {Flashcards - {{QBWiki}}},
  author = {Jackson, Matt},
  howpublished = {https://www.qbwiki.com/wiki/Flashcards},
  file = {/Users/mattshu/Zotero/storage/6SYC9GLB/Flashcards.html}
}

@inbook{jenkinsFourPointsRemember1979,
  title = {Four {{Points}} to {{Remember}}: {{A Tetrahedral Model}} of {{Memory Experiments}}},
  booktitle = {Levels of Processing in Human Memory},
  author = {Jenkins, James Jerome},
  year = {1979},
  collaborator = {Cermak, Laird S and Craik, Fergus I. M},
  isbn = {978-1-317-74979-0 978-1-317-74980-6 978-1-317-74978-3 978-1-315-79619-2 978-1-315-77503-6},
  language = {English},
  annotation = {OCLC: 880401125}
}

@article{jenkinsObliviscenceSleepWaking1924,
  title = {Obliviscence {{During Sleep}} and {{Waking}}},
  author = {Jenkins, J. G. and Dallenbach, K. M.},
  year = {1924},
  journal = {The American Journal of Psychology},
  volume = {35},
  pages = {605--612},
  publisher = {{Univ of Illinois Press}},
  address = {{US}},
  issn = {1939-8298(Electronic),0002-9556(Print)},
  doi = {10.2307/1414040},
  abstract = {The observers in this experiment learned series of nonsense syllables either in the morning or else in the evening just before retiring, and were tested for their memory of the series 1, 2, 4 or 8 hours later. The learning was to complete mastery and the test by the method of retained members. When the series were learned at night, the time between learning and reproduction was spent in sleep; in the other case the observers were awake during the intervening period. The results show a much slower rate of forgetting during sleep than during waking. The curve for forgetting during sleep has a short initial decline, after which a constant level is maintained, while that for the periods of waking takes the familiar form of a continued decline which is negatively accelerated. This divergence in the rate of forgetting during sleep and waking accounts for the variations found in the curves of forgetting of earlier investigators. From Psych Bulletin 22:09:00714. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  file = {/Users/mattshu/Zotero/storage/FFCR27AS/1926-08168-001.html}
}

@article{kangSpacedRepetitionPromotes2016,
  title = {Spaced {{Repetition Promotes Efficient}} and {{Effective Learning}}: {{Policy Implications}} for {{Instruction}}},
  shorttitle = {Spaced {{Repetition Promotes Efficient}} and {{Effective Learning}}},
  author = {Kang, Sean H. K.},
  year = {2016},
  month = mar,
  journal = {Policy Insights from the Behavioral and Brain Sciences},
  volume = {3},
  number = {1},
  pages = {12--19},
  issn = {2372-7322, 2372-7330},
  doi = {10.1177/2372732215624708},
  abstract = {Concern that students in the United States are less proficient in mathematics, science, and reading than their peers in other countries has led some to question whether American students spend enough time in school. Instead of debating the amount of time that should be spent in school (and on schoolwork), this article addresses how the available instructional time might be optimally utilized via the scheduling of review or practice. Hundreds of studies in cognitive and educational psychology have demonstrated that spacing out repeated encounters with the material over time produces superior long-term learning, compared with repetitions that are massed together. Also, incorporating tests into spaced practice amplifies the benefits. Spaced review or practice enhances diverse forms of learning, including memory, problem solving, and generalization to new situations. Spaced practice is a feasible and cost-effective way to improve the effectiveness and efficiency of learning, and has tremendous potential to improve educational outcomes. The article also discusses barriers to adopting spaced practice, recent developments, and their possible implications.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Kang_2016_Spaced Repetition Promotes Efficient and Effective Learning.pdf}
}

@article{karpickeRetrievalPracticeProduces2011,
  ids = {karpickeRetrievalPracticeProduces2011b},
  title = {Retrieval {{Practice Produces More Learning}} than {{Elaborative Studying}} with {{Concept Mapping}}},
  author = {Karpicke, Jeffrey D. and Blunt, Janell R.},
  year = {2011},
  month = feb,
  journal = {Science},
  volume = {331},
  number = {6018},
  pages = {772--775},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1199327},
  abstract = {Educators rely heavily on learning activities that encourage elaborative studying, whereas activities that require students to practice retrieving and reconstructing knowledge are used less frequently. Here, we show that practicing retrieval produces greater gains in meaningful learning than elaborative studying with concept mapping. The advantage of retrieval practice generalized across texts identical to those commonly found in science education. The advantage of retrieval practice was observed with test questions that assessed comprehension and required students to make inferences. The advantage of retrieval practice occurred even when the criterial test involved creating concept maps. Our findings support the theory that retrieval practice enhances learning by retrieval-specific mechanisms rather than by elaborative study processes. Retrieval practice is an effective tool to promote conceptual learning about science. Two different ways of thinking through texts are compared for learning value. Two different ways of thinking through texts are compared for learning value.},
  chapter = {Report},
  copyright = {Copyright \textcopyright{} 2011, American Association for the Advancement of Science},
  language = {en},
  pmid = {21252317},
  keywords = {Biological Science Disciplines,Cues,Educational Measurement,Humans,Learning,Memory,Mental Recall,Test Taking Skills},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Karpicke_Blunt_2011_Retrieval Practice Produces More Learning than Elaborative Studying with.pdf;/Users/mattshu/Zotero/storage/6F7ACJR4/772.html;/Users/mattshu/Zotero/storage/TCLKPFC9/772.html;/Users/mattshu/Zotero/storage/YDKXHNJM/772.html}
}

@article{kornellOptimisingLearningUsing2009,
  title = {Optimising Learning Using Flashcards: {{Spacing}} Is More Effective than Cramming},
  shorttitle = {Optimising Learning Using Flashcards},
  author = {Kornell, Nate},
  year = {2009},
  journal = {Applied Cognitive Psychology},
  volume = {23},
  number = {9},
  pages = {1297--1317},
  issn = {1099-0720},
  doi = {10.1002/acp.1537},
  abstract = {The spacing effect\textemdash that is, the benefit of spacing learning events apart rather than massing them together\textemdash has been demonstrated in hundreds of experiments, but is not well known to educators or learners. I investigated the spacing effect in the realistic context of flashcard use. Learners often divide flashcards into relatively small stacks, but compared to a large stack, small stacks decrease the spacing between study trials. In three experiments, participants used a web-based study programme to learn GRE-type word pairs. Studying one large stack of flashcards (i.e. spacing) was more effective than studying four smaller stacks of flashcards separately (i.e. massing). Spacing was also more effective than cramming\textemdash that is, massing study on the last day before the test. Across experiments, spacing was more effective than massing for 90\% of the participants, yet after the first study session, 72\% of the participants believed that massing had been more effective than spacing. Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd.},
  copyright = {Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Kornell_2009_Optimising learning using flashcards.pdf;/Users/mattshu/Zotero/storage/374DCRWC/acp.html}
}

@misc{LearningToolsFlashcards,
  title = {Learning Tools \& Flashcards, for Free | {{Quizlet}}},
  howpublished = {https://quizlet.com/},
  file = {/Users/mattshu/Zotero/storage/9KZ58TWR/quizlet.com.html}
}

@book{leitnerLerntManLernen1972,
  title = {{So lernt man lernen: Angewandte Lernpsychologie ein Weg zum Erfolg}},
  author = {Leitner, Sebastian},
  year = {1972},
  publisher = {{Herder}},
  googlebooks = {sD3AAQAACAAJ},
  isbn = {978-3-451-16265-7},
  language = {de}
}

@article{lewis-krausGreatAwakening2016,
  title = {The {{Great A}}.{{I}}. {{Awakening}}},
  author = {{Lewis-Kraus}, Gideon},
  year = {2016},
  month = dec,
  journal = {The New York Times},
  issn = {0362-4331},
  abstract = {How Google used artificial intelligence to transform Google Translate, one of its more popular services \textemdash{} and how machine learning is poised to reinvent computing itself.},
  chapter = {Magazine},
  language = {en-US},
  keywords = {Artificial Intelligence,Computers and the Internet,Dean; Jeff (1968- ),Google Inc,Hinton; Geoffrey E,Lewis-Kraus; Gideon,Pichai; Sundar,Translation and Interpreters,Voice Recognition Systems},
  file = {/Users/mattshu/Zotero/storage/FBHKJ67V/the-great-ai-awakening.html}
}

@article{lindseyImprovingStudentsLongTerm2014,
  title = {Improving {{Students}}' {{Long}}-{{Term Knowledge Retention Through Personalized Review}}},
  author = {Lindsey, Robert V. and Shroyer, Jeffery D. and Pashler, Harold and Mozer, Michael C.},
  year = {2014},
  month = mar,
  journal = {Psychol Sci},
  volume = {25},
  number = {3},
  pages = {639--647},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797613504302},
  abstract = {Human memory is imperfect; thus, periodic review is required for the long-term preservation of knowledge and skills. However, students at every educational level are challenged by an ever-growing amount of material to review and an ongoing imperative to master new material. We developed a method for efficient, systematic, personalized review that combines statistical techniques for inferring individual differences with a psychological theory of memory. The method was integrated into a semester-long middle-school foreign-language course via retrieval-practice software. Using a cumulative exam administered after the semester's end, we compared time-matched review strategies and found that personalized review yielded a 16.5\% boost in course retention over current educational practice (massed study) and a 10.0\% improvement over a one-size-fits-all strategy for spaced study.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Lindsey et al_2014_Improving Studentsâ€™ Long-Term Knowledge Retention Through Personalized Review.pdf}
}

@misc{matuschakQuantumComputingVery2019,
  title = {Quantum Computing for the Very Curious},
  author = {Matuschak, Andy and Nielsen, Michael A.},
  year = {2019},
  abstract = {Presented in an experimental mnemonic medium that makes it almost effortless to remember what you read},
  howpublished = {https://quantum.country/qcvc},
  file = {/Users/mattshu/Zotero/storage/CVUE2AIF/qcvc.html}
}

@article{mcgaughMemoryCenturyConsolidation2000,
  title = {Memory--a {{Century}} of {{Consolidation}}},
  author = {McGaugh, James L.},
  year = {2000},
  month = jan,
  journal = {Science},
  volume = {287},
  number = {5451},
  pages = {248--251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.287.5451.248},
  abstract = {The memory consolidation hypothesis proposed 100 years ago by M\"uller and Pilzecker continues to guide memory research. The hypothesis that new memories consolidate slowly over time has stimulated studies revealing the hormonal and neural influences regulating memory consolidation, as well as molecular and cellular mechanisms. This review examines the progress made over the century in understanding the time-dependent processes that create our lasting memories.},
  chapter = {Review},
  language = {en},
  pmid = {10634773},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/McGaugh_2000_Memory--a Century of Consolidation.pdf;/Users/mattshu/Zotero/storage/2ULKXNZ3/248.html}
}

@article{meltonSituationRespectSpacing1970,
  title = {The Situation with Respect to the Spacing of Repetitions and Memory},
  author = {Melton, Arthur W.},
  year = {1970},
  journal = {Journal of Verbal Learning and Verbal Behavior},
  pages = {596--606},
  abstract = {The revival of interest in the effectiveness of spaced practice, as compared with massed practice, in learning is attributed tothe abandonment of the constraints ofserial and paired-associate list learning and the discovery of stable benefits from spaced practice in continuous paired-associate learning, short-term emory for individual items, and single-trial free-recall learning. Comments are made about the preceding symposium papers by Underwood, Waugh, and Greeno,,and some data on the differential effects of spacing of repetitions in free-recall earning are introduced inan effort o assess the current state of fact and theory. Before looking at the data and theories that have been presented at this symposium, it seems to me worthwhile to consider how we have gotten to where we are today in the examination of the question of the relative effectiveness of massed practice (MP) and distributed practice (DP), and why. I will not trace the history of research on MP},
  keywords = {_tablet,settles},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Melton_1970_The situation with respect to the spacing of repetitions and memory.pdf;/Users/mattshu/Zotero/storage/7YANYGLA/summary.html}
}

@misc{mooneySpacedRepetitionAll2017,
  title = {Spaced {{Repetition}} for {{All}}: {{Cognitive Science Meets Big Data}} in a {{Procrastinating World}}},
  shorttitle = {Spaced {{Repetition}} for {{All}}},
  author = {Mooney, Shane},
  year = {2017},
  month = mar,
  journal = {Quizlet},
  abstract = {Here at Quizlet, our goal is to help students practice and master whatever they're learning \textemdash{} and to do it as efficiently as possible. Research shows that the most effective way to learn involves spreading study out over a long period of time and reviewing terms with longer and longer delays each time, a process known as spaced repetition. However, students don't always have the luxury of spending days or weeks repeatedly reviewing material. They've got a test tomorrow, and they need to learn the material now. So our challenge is: How can we present learning material so students are always focusing on whatever they need to work on the most? With that goal in mind, we set out to build a brand new framework for choosing and ordering terms to study on Quizlet. We call it the Learning Assistant Platform. It powers the new Learn, which launches today on iOS, and soon on Android and Web! We aim to have this algorithm drive the question selection for many of the learning experiences on Quizlet. Existing Solutions Classic Quizlet Learn The original Quizlet Learn had a very simple algorithm: Answer one question for every term, repeat all the questions you got wrong, and continue until you've gotten each question correct. This is a great start, but it's usually not enough to be ready for a test. We took a look at a small sample of all the answers on Quizlet and saw that after getting a term correct on the first try, once a user sees it a second time (whenever that may be), there's only about an 87\% chance they'll get it right. And if it took a few tries to get right, that number drops much lower: below 70\%. Students could keep studying by restarting Learn from the beginning, but now they're spending a lot of time re-studying terms they already know fairly well instead of focusing on the ones that need more work. That's not the most efficient use of time, and we knew we could improve on that. Long-Term Learning About a year ago, Quizlet launched Long-Term Learning. Long-Term Learning uses a standard spaced repetition algorithm, similar to SuperMemo or Anki. It works something like this: Introduce a few new terms each day Study all of the day's terms until you get them all correct, then study the new terms again the next day Each time a term is answered correctly, increase the delay until it's studied again by a little more than double (Study 1 day later, 3 days after that, then 7 days, 16 days, etc.) If a term is answered incorrectly, start over and reset the delay for that term to 1 day Long-Term Learning works great when there's no particular deadline for when a student needs to finish learning the material. By deferring review of each term until just as it's about to be forgotten, Long-Term Learning minimizes the effort needed to commit the terms to long-term memory. However, it won't allow students to study all their terms in a single day, nor to review a term after they've already studied it in a given day. This is great for the students who have long-term study goals. However, the majority of Quizlet users only study a set on a single day; 95\% study a set over four days at most, which is still too few for the Long-Term Learning algorithm to be effective. Cramming is a reality for many students, and we want to help them make the best of their study time however they spend it. Our Approach A key idea behind spaced repetition is that a student should always study a term just before they're about to forget it, when there's about an 80\% chance to get the answer correct. But at Quizlet we can't wait long enough for students to almost forget some terms. Many students don't have the time, and even if they did, we wouldn't want them going into a test with only an 81\% chance of getting the answers right! So instead, our new Learning Assistant algorithm prioritizes the terms we think students are closest to forgetting, the terms we think the student is least likely to get correct. So every question a student sees is always on one of the few terms that need the most work, and within that framework, we can build a term scheduling algorithm that works well for any time scale. So how do we know which terms a student is most likely to forget? That's where machine learning comes into play. Quizlet has tens of millions of users who have submitted tens of billions of answers on billions of terms. For each user's answer, we know which term they were studying, what time they answered it, and whether they got the question correct or incorrect. We started by sampling a small subset of about 1.5 million answers from our database and grouped them into streaks for each user, on each term. Then we looked for patterns that correlate with higher or lower recall probability \textemdash{} a user's chance to answer a term correctly at a given time. Finally, we were able to use that model in our new Learning Assistant algorithm to predict recall probability and prioritize the lowest scored terms. Identifying the Features Any machine learning algorithm must start by identifying ``features'': Pieces of information from which the algorithm can learn to make predictions. Our algorithm has four main features we use to predict recall probability: Correctness of answers Time since last answer Time between previous answers Direction of study Answer Correctness Three answers, two incorrect, and one correct Unsurprisingly, the single strongest predictor of whether the next question will be answered correctly is whether or not the most recent answer for the term was correct. But whether or not older answers were correct is also very important. The farther back the answer was, the less it influences the chances of getting the upcoming question correct. Two wrong answers followed by a correct answer is very different from a correct answer followed by two wrong answers. Recall probability for all possible answer sequences up to three deep This feature is the key to allowing us to determine what terms need to be reviewed the most, even if they were all studied very recently. Forgetting Curve: Time Since Last Question Three answers, some time ago The longer it's been since a student saw a term, the less likely they are to remember it. This is known to follow an exponential decay function, called the forgetting curve. The forgetting curve is one of two key cognitive science principles that inform the design of all spaced repetition algorithms. Here's our model of the forgetting curve for a typical case: Our predictions of recall probability will decay over time as the student starts to forget a term, leading us to prioritize terms that haven't been studied recently. Spacing Effect: Time Between Previous Questions Three answers, with some delay between the most recent two The more a student spaces out their study, the better they'll remember the material. This is known as the spacing effect. This is another cognitive science principle behind the idea of spaced repetition. We measure the time between the previous two answers, and like the forgetting curve, we assume an exponential relationship. If students space their study out over longer periods of time, as opposed to cramming in a single sitting, we'll expect them to remember the terms better, and won't need to ask them to study the terms as many times. Study Direction Just because a student can remember the English definition for a Spanish word doesn't necessarily mean they'll be able to remember the Spanish word when given the English definition. We treat each direction you can study a term as separate but related facts. If a student only studies a term in one direction, they'll be less likely to get that term correct in the other direction. As a result, we tend to ask the question side the student has seen and gotten correct less often, making sure the student learns the term front and back! The Model Finally, with all these features derived from over a million answers, we trained a machine learning model to predict recall probability using logistic regression. Logistic regression finds an equation that takes each of the features as an input and returns a number between 0 and 1. For us, 0 represents an incorrect answer and 1 represents a correct answer. Logistic regression attempts to minimize the error between the predictions it generates and the actual observed results. We can interpret these predictions as recall probability, which then we use to determine the best ordering of questions. Our model performed pretty well! A standard approach for evaluating a model like this is the AUROC metric. A value of 1 would indicate perfect predictions, and 0.5 would indicate random guessing. Our AUROC was 0.815, which is pretty good. Because we know our predictions are fairly accurate, we can be confident that the lowest scored terms really are the ones that need the most work. While there are other, more sophisticated machine learning algorithms available, we chose logistic regression for two reasons: First, it produces a very simple, easy to interpret model, allowing us to understand and quantify how these variables affect learning. Second, and more important for us, is model portability. Quizlet is used in many different environments around the world \textemdash{} on the road, in developing countries, and in schools with limited network capacity. Our goal is to make quality learning tools accessible to every student, so robust offline support in our mobile apps is a priority. Logistic regression produces a simple equation that we can transcribe to a JavaScript module that we can use on the website and compile into both the iOS and Android apps, putting the power of machine learning in your pocket! Future Improvements Now that we've launched this for new Learn, we're excited to see the results and improve on them. Within this framework, there's a lot more we can do to make the algorithm even better! Here's some of the ideas we have in mind: Better modeling of different question types Before now, Quizlet hasn't had a learning experience with the mix of question types we have in the new Learn (which includes multiple choice, self-assessment flashcards, and others). We trained our model on old Learn, which includes only written questions, so it isn't able to capture the fact that multiple choice questions are easier than written questions, for example. Once we develop a model for the new question types, we'll be able to quantify how well studying with each question type prepares a student to answer written questions. Measuring inherent difficulty of terms Some terms are just going to be harder than others, regardless of how they're studied or who's studying them. For example, one might expect words with irregular spellings to be more difficult to remember. We can look at each word that's commonly studied on Quizlet, measure how often users get it correct, and use that to make better term ordering decisions, even for people who haven't started studying the material. Improving behavior over longer periods of time Because our algorithm is based on the principles of spaced repetition, it should in theory behave like other spaced repetition algorithms and, over the course of many days, introduce longer and longer delays between each time a term is studied. However, in practice, because we assumed a simple exponential decay forgetting curve and trained our model on a random sample of Quizlet data which is heavily biased towards time ranges of under a couple days, our model isn't very sensitive to time changes over longer periods of time. But we can address that by sampling our data to include more long-term study behavior, and by modelling the time components more flexibly (not assuming a strict exponential relationship). That will allow us to build an algorithm that works great whether a student crams studying ten terms the night before a test, or spends years studying thousands of terms. Moving Forward The Quizlet Learning Assistant Platform paves the way forward for more intelligent and efficient learning on Quizlet. The classic Learn algorithm is simple but not efficient, and the Long-Term Learning algorithm only works well for students without deadlines. By using machine learning to build a predictive model informed by the same cognitive science theories behind spaced repetition, we were able to build an algorithm that makes studying efficient and practical for all our users. We're excited to launch this as part of the new Learn, and we're looking forward to continuing to improve it in the future!},
  howpublished = {https://quizlet.com/blog/spaced-repetition-for-all-cognitive-science-meets-big-data-in-a-procrastinating-world},
  language = {en-us},
  file = {/Users/mattshu/Zotero/storage/VQLXZ7ES/spaced-repetition-for-all-cognitive-science-meets-big-data-in-a-procrastinating-world.html}
}

@article{mozerArtificialIntelligenceSupport2019,
  title = {Artificial Intelligence to Support Human Instruction},
  author = {Mozer, Michael C. and Wiseheart, Melody and Novikoff, Timothy P.},
  year = {2019},
  month = mar,
  journal = {Proc Natl Acad Sci USA},
  volume = {116},
  number = {10},
  pages = {3953--3955},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1900370116},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Mozer et al_2019_Artificial intelligence to support human instruction.pdf}
}

@incollection{mozerPredictingImprovingMemory2016,
  title = {Predicting and {{Improving Memory Retention}}: {{Psychological Theory Matters}} in the {{Big Data Era}}},
  shorttitle = {Predicting and {{Improving Memory Retention}}},
  booktitle = {Big {{Data}} in {{Cognitive Science}}},
  author = {Mozer, Michael C. and Lindsey, Robert V.},
  year = {2016},
  month = nov,
  edition = {Zeroth},
  pages = {43--73},
  publisher = {{Psychology Press}},
  address = {{New York, NY : Routledge, 2016. |}},
  doi = {10.4324/9781315413570-8},
  isbn = {978-1-315-41357-0},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Mozer_Lindsey_2016_Predicting and Improving Memory Retention.pdf}
}

@article{murreReplicationAnalysisEbbinghaus2015,
  title = {Replication and {{Analysis}} of {{Ebbinghaus}}' {{Forgetting Curve}}},
  author = {Murre, Jaap M. J. and Dros, Joeri},
  year = {2015},
  month = jul,
  journal = {PLOS ONE},
  volume = {10},
  number = {7},
  pages = {e0120644},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0120644},
  abstract = {We present a successful replication of Ebbinghaus' classic forgetting curve from 1880 based on the method of savings. One subject spent 70 hours learning lists and relearning them after 20 min, 1 hour, 9 hours, 1 day, 2 days, or 31 days. The results are similar to Ebbinghaus' original data. We analyze the effects of serial position on forgetting and investigate what mathematical equations present a good fit to the Ebbinghaus forgetting curve and its replications. We conclude that the Ebbinghaus forgetting curve has indeed been replicated and that it is not completely smooth but most probably shows a jump upwards starting at the 24 hour data point.},
  language = {en},
  keywords = {_tablet,Curve fitting,Experimental psychology,Exponential functions,Learning,Learning curves,Memory recall,Replication studies,Syllables,to read},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Murre_Dros_2015_Replication and Analysis of Ebbinghausâ€™ Forgetting Curve.pdf;/Users/mattshu/Zotero/storage/R648HDKY/article.html}
}

@article{nakataComputerassistedSecondLanguage2011,
  title = {Computer-Assisted Second Language Vocabulary Learning in a Paired-Associate Paradigm: A Critical Investigation of Flashcard Software},
  shorttitle = {Computer-Assisted Second Language Vocabulary Learning in a Paired-Associate Paradigm},
  author = {Nakata, Tatsuya},
  year = {2011},
  month = feb,
  journal = {Computer Assisted Language Learning},
  volume = {24},
  number = {1},
  pages = {17--38},
  issn = {0958-8221, 1744-3210},
  doi = {10.1080/09588221.2010.520675},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Nakata_2011_Computer-assisted second language vocabulary learning in a paired-associate.pdf}
}

@article{nielsenAugmentingLongtermMemory2018,
  title = {Augmenting {{Long}}-Term {{Memory}}},
  author = {Nielsen, Michael},
  year = {2018},
  file = {/Users/mattshu/Zotero/storage/N9AXB6AG/ltm.html}
}

@article{nielsenIterativeUserinterfaceDesign1993,
  title = {Iterative User-Interface Design},
  author = {Nielsen, J.},
  year = {1993},
  month = nov,
  journal = {Computer},
  volume = {26},
  number = {11},
  pages = {32--41},
  issn = {1558-0814},
  doi = {10.1109/2.241424},
  abstract = {A method for developing user interfaces by refining them iteratively over several versions is presented. Each iteration is subjected to user testing or other usability-evaluation methods designed to uncover usability problems. This method not only eliminates problems of this nature, but also allows designers to take advantage of any insights into user needs that emerge from the tests. The author describes four case studies where the median improvement in overall usability from the first to the last iteration was 165\%, and the median improvement per iteration was 38\%.{$<>$}},
  keywords = {_tablet,Costs,Design engineering,Design methodology,Gain measurement,Iterative methods,iterative user interface design,Life testing,Performance evaluation,System testing,to read,Usability,usability-evaluation methods,user interfaces,User interfaces,user testing},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Nielsen_1993_Iterative user-interface design.pdf;/Users/mattshu/Zotero/storage/82YWR3YS/241424.html}
}

@article{novikoffEducationModelStudent2012,
  title = {Education of a Model Student.},
  author = {Novikoff, T. P. and Kleinberg, J. M. and Strogatz, S. H.},
  year = {2012},
  month = feb,
  journal = {Proc Natl Acad Sci U S A},
  volume = {109},
  number = {6},
  pages = {1868--1873},
  issn = {0027-8424},
  doi = {10.1073/pnas.1109863109},
  abstract = {Abstract: A dilemma faced by teachers, and increasingly by designers of educational software, is the trade-off between teaching new material and reviewing...},
  language = {eng},
  keywords = {_tablet,reddy},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Novikoff et al_2012_Education of a model student.pdf;/Users/mattshu/Zotero/storage/CAR725Y5/22308334.html}
}

@misc{OpenAPISpecification,
  title = {{{OpenAPI}} 3.0.3 {{Specification}}},
  howpublished = {https://swagger.io/specification/},
  file = {/Users/mattshu/Zotero/storage/Q22HTN3G/specification.html}
}

@misc{papousekAnalysisHalflifeRegression,
  type = {Blog},
  title = {Analysis of {{Half}}-Life {{Regression Model Made}} by {{Duolingo}}},
  author = {Papousek, Jan},
  howpublished = {https://papousek.github.io/analysis-of-half-life-regression-model-made-by-duolingo.html},
  file = {/Users/mattshu/Zotero/storage/5ZSQLL6B/analysis-of-half-life-regression-model-made-by-duolingo.html}
}

@article{pashlerPredictingOptimalSpacing2009,
  title = {Predicting the {{Optimal Spacing}} of {{Study}}: {{A Multiscale Context Model}} of {{Memory}}},
  shorttitle = {Predicting the {{Optimal Spacing}} of {{Study}}},
  author = {Pashler, Harold and Cepeda, Nicholas and Lindsey, Robert V. and Vul, Ed and Mozer, Michael C.},
  year = {2009},
  journal = {Advances in Neural Information Processing Systems},
  volume = {22},
  pages = {1321--1329},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Pashler et al_2009_Predicting the Optimal Spacing of Study.pdf;/Users/mattshu/Zotero/storage/SGBTJN2Z/6bc24fc1ab650b25b4114e93a98f1eba-Abstract.html}
}

@article{passanteCatCradleBrings,
  title = {`{{Cat}}'s in the {{Cradle}}' Brings Generations Together. {{In}} Shuddering Sobs.},
  author = {Passante, Robyn},
  journal = {Washington Post},
  issn = {0190-8286},
  abstract = {My 9-year-old was inconsolable over Chapin's folk hit from the '70s, blubbering between cries about what a tragically sad song it is and saying that he doesn't want to grow up. Like, ever.},
  language = {en-US},
  file = {/Users/mattshu/Zotero/storage/5PF97ITK/cats-in-the-cradle-brings-generations-together-in-shuddering-sobs.html}
}

@article{pavlikPracticeForgettingEffects2005,
  title = {Practice and Forgetting Effects on Vocabulary Memory: An Activation-Based Model of the Spacing Effect},
  shorttitle = {Practice and Forgetting Effects on Vocabulary Memory},
  author = {Pavlik, Philip I. and Anderson, John R.},
  year = {2005},
  month = jul,
  journal = {Cogn Sci},
  volume = {29},
  number = {4},
  pages = {559--586},
  issn = {0364-0213},
  doi = {10.1207/s15516709cog0000_14},
  abstract = {An experiment was performed to investigate the effects of practice and spacing on retention of Japanese-English vocabulary paired associates. The relative benefit of spacing increased with increased practice and with longer retention intervals. Data were fitted with an activation-based memory model, which proposes that each time an item is practiced it receives an increment of strength but that these increments decay as a power function of time. The rate of decay for each presentation depended on the activation at the time of the presentation. This mechanism limits long-term benefits from further practice at higher levels of activation and produces the spacing effect and its observed interactions with practice and retention interval. The model was compared with another model of the spacing effect (Raaijmakers, 2003) and was fit to some results from the literature on spacing and memory.},
  language = {eng},
  pmid = {21702785},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Pavlik_Anderson_2005_Practice and forgetting effects on vocabulary memory.pdf}
}

@article{pelanekMetricsEvaluationStudent2015,
  title = {Metrics for {{Evaluation}} of {{Student Models}}},
  author = {Pelanek, Radek},
  year = {2015},
  month = jun,
  publisher = {{Zenodo}},
  doi = {10.5281/ZENODO.3554665},
  abstract = {Researchers use many different metrics for evaluation of performance of student models. The aim of this paper is to provide an overview of commonly used metrics, to discuss properties, advantages, and disadvantages of different metrics, to summarize current practice in educational data mining, and to provide guidance for evaluation of student models. In the discussion we mention the relation of metrics to parameter fitting, the impact of student models on student practice (over-practice, under-practice), and point out connections to related work on evaluation of probability forecasters in other domains. We also provide an empirical comparison of metrics. One of the conclusion of the paper is that some commonly used metrics should not be used (MAE) or should be used more critically (AUC).},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International, Open Access},
  language = {en},
  keywords = {metrics for evaluation,parameter fitting,performance of student models,probability forecasters,student practice},
  file = {/Users/mattshu/Zotero/storage/VYRBEQLK/metrics.pdf}
}

@inproceedings{penningtonGloveGlobalVectors2014,
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  shorttitle = {Glove},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  year = {2014},
  pages = {1532--1543},
  publisher = {{Association for Computational Linguistics}},
  address = {{Doha, Qatar}},
  doi = {10.3115/v1/D14-1162},
  abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75\% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Pennington et al_2014_Glove.pdf}
}

@article{pimsleurMemorySchedule1967,
  title = {A {{Memory Schedule}}},
  author = {Pimsleur, Paul},
  year = {1967},
  journal = {The Modern Language Journal},
  volume = {51},
  number = {2},
  pages = {73--75},
  publisher = {{[National Federation of Modern Language Teachers Associations, Wiley]}},
  issn = {0026-7902},
  doi = {10.2307/321812}
}

@misc{ramirezFastAPIPostgreSQLFullStack2020,
  title = {{{FastAPI}}-{{PostgreSQL Full Stack Template}}},
  author = {Ram{\'i}rez, Sebasti{\'a}n},
  year = {2020},
  month = apr,
  abstract = {Full stack, modern web application generator. Using FastAPI, PostgreSQL as database, Docker, automatic HTTPS and more.},
  copyright = {MIT},
  keywords = {backend,celery,cookiecutter,docker,fastapi,frontend,json,json-schema,jwt,letsencrypt,openapi,openapi3,pgadmin,postgresql,python,python3,swagger,traefik,vue,vuex}
}

@article{reddyAcceleratingHumanLearning,
  title = {Accelerating {{Human Learning}} with {{Deep Reinforcement Learning}}},
  author = {Reddy, Siddharth and Levine, Sergey and Dragan, Anca},
  pages = {9},
  abstract = {Guiding a student through a sequence of lessons and helping them retain knowledge is one of the central challenges in education. Online learning platforms like Khan Academy and Duolingo tackle this problem in part by using interaction data to estimate student proficiency and recommend content. While the literature proposes a variety of algorithms for modeling student learning, there is relatively little work on principled methods for sequentially choosing items for the student to review in order to maximize learning. We study this decision problem as an instance of reinforcement learning, and draw on recent advances in training deep neural networks to learn flexible and scalable teaching policies that select the next item to review. Our primary contribution is an analysis of a model-free review scheduling algorithm for spaced repetition systems that does not explicitly model the student, and instead learns a policy that directly operates on raw observations of the study history. As a preliminary study, we train and evaluate this method using a student simulator based on cognitive models of human memory. Results show that modelfree scheduling is competitive against widely-used heuristics like SuperMemo and the Leitner system on various learning objectives and student models.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Reddy et al_Accelerating Human Learning with Deep Reinforcement Learning.pdf}
}

@misc{reddyRddyDeeptutor2020,
  title = {Rddy/Deeptutor},
  author = {Reddy, Sid},
  year = {2020},
  month = nov,
  abstract = {Spaced repetition through deep reinforcement learning},
  copyright = {MIT License         ,                 MIT License}
}

@inproceedings{reddyUnboundedHumanLearning2016,
  title = {Unbounded {{Human Learning}}: {{Optimal Scheduling}} for {{Spaced Repetition}}},
  shorttitle = {Unbounded {{Human Learning}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}} - {{KDD}} '16},
  author = {Reddy, Siddharth and Labutov, Igor and Banerjee, Siddhartha and Joachims, Thorsten},
  year = {2016},
  pages = {1815--1824},
  publisher = {{ACM Press}},
  address = {{San Francisco, California, USA}},
  doi = {10.1145/2939672.2939850},
  abstract = {In the study of human learning, there is broad evidence that our ability to retain information improves with repeated exposure and decays with delay since last exposure. This plays a crucial role in the design of educational software, leading to a trade-off between teaching new material and reviewing what has already been taught. A common way to balance this trade-off is spaced repetition, which uses periodic review of content to improve long-term retention. Though spaced repetition is widely used in practice, e.g., in electronic flashcard software, there is little formal understanding of the design of these systems. Our paper addresses this gap in three ways. First, we mine log data from spaced repetition software to establish the functional dependence of retention on reinforcement and delay. Second, we use this memory model to develop a stochastic model for spaced repetition systems. We propose a queueing network model of the Leitner system for reviewing flashcards, along with a heuristic approximation that admits a tractable optimization problem for review scheduling. Finally, we empirically evaluate our queueing model through a Mechanical Turk experiment, verifying a key qualitative prediction of our model: the existence of a sharp phase transition in learning outcomes upon increasing the rate of new item introductions.},
  isbn = {978-1-4503-4232-2},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Reddy et al_2016_Unbounded Human Learning.pdf}
}

@incollection{roberta.bjorkMemoryMetamemoryConsiderations1994,
  title = {Memory and Metamemory Considerations in the Training of Human Beings},
  booktitle = {Metacognition: {{Knowing}} about {{Knowing}}},
  author = {{Robert A. Bjork}},
  editor = {{Janet Metcalfe} and {Arthur P. Shimamura}},
  year = {1994},
  month = apr,
  publisher = {{MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {Metacognition offers an up-to-date compendium of major scientific issues involved in metacognition. The twelve original contributions provide a concise statement of theoretical and empirical research on self-reflective processes or knowing about what we know.Self-reflective processes are often thought to be central to what we mean by consciousness and the personal self. Without such processes, one would presumably respond to stimuli in an automatized and environmentally bound manner -- that is, without the characteristic patterns of behavior and introspection that are manifested as plans, strategies, reflections, self-control, self-monitoring, and intelligence.A Bradford Book},
  googlebooks = {Ci0TDgAAQBAJ},
  isbn = {978-0-262-13298-5},
  language = {en},
  keywords = {Psychology / Cognitive Psychology \& Cognition}
}

@misc{rodriguezHumanCentricMachineLearning,
  title = {Human-{{Centric Machine Learning}}: {{Feedback}} Loops, {{Human}}-{{AI}} Collaboration and Strategic Behavior},
  author = {Rodriguez, Manuel},
  howpublished = {https://people.mpi-sws.org/\textasciitilde manuelgr/manuelgr-human-centric-ml-2020.pdf},
  keywords = {_tablet},
  file = {/Users/mattshu/Zotero/storage/XVCUKUNL/Rodriguez_Human-Centric Machine Learning.pdf}
}

@article{rodriguezQuizbowlCaseIncremental2019,
  title = {Quizbowl: {{The Case}} for {{Incremental Question Answering}}},
  shorttitle = {Quizbowl},
  author = {Rodriguez, Pedro and Feng, Shi and Iyyer, Mohit and He, He and {Boyd-Graber}, Jordan},
  year = {2019},
  month = apr,
  journal = {arXiv:1904.04792 [cs]},
  eprint = {1904.04792},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Quizbowl is a scholastic trivia competition that tests human knowledge and intelligence; additionally, it supports diverse research in question answering (QA). A Quizbowl question consists of multiple sentences whose clues are arranged by difficulty (from obscure to obvious) and uniquely identify a well-known entity such as those found on Wikipedia. Since players can answer the question at any time, an elite player (human or machine) demonstrates its superiority by answering correctly given as few clues as possible. We make two key contributions to machine learning research through Quizbowl: (1) collecting and curating a large factoid QA dataset and an accompanying gameplay dataset, and (2) developing a computational approach to playing Quizbowl that involves determining both what to answer and when to answer. Our Quizbowl system has defeated some of the best trivia players in the world over a multi-year series of exhibition matches. Throughout this paper, we show that collaborations with the vibrant Quizbowl community have contributed to the high quality of our dataset, led to new research directions, and doubled as an exciting way to engage the public with research in machine learning and natural language processing.},
  archiveprefix = {arXiv},
  keywords = {_tablet,Computer Science - Computation and Language},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Rodriguez et al_2019_Quizbowl.pdf;/Users/mattshu/Zotero/storage/QN4DL6TA/1904.html}
}

@article{roedigerHypermnesiaRoleRepeated1982,
  title = {Hypermnesia: {{The}} Role of Repeated Testing},
  shorttitle = {Hypermnesia},
  author = {Roediger, Henry L. and Payne, David G.},
  year = {1982},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {8},
  number = {1},
  pages = {66--72},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/0278-7393.8.1.66},
  abstract = {Determined whether the increased recall of pictures across repeated tests (hypermnesia) was due to increasing strength of imaginal traces during the retention interval or to increased retrieval practice from prior tests. 120 undergraduates studied 60 pictures and then recalled them after various delays that were filled with instructions and, in 2 cases, reading a passage. Recall on a 1st test showed no change with retention interval. With retention interval held constant, however, the number of pictures recalled varied directly with the number of prior tests Ss had been given. Implications of the critical nature of retrieval factors in producing hypermnesia are discussed. (22 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Pictorial Stimuli,Practice,Recall (Learning),Testing},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Roediger_Payne_1982_Hypermnesia.pdf;/Users/mattshu/Zotero/storage/Y4KLPPTX/1982-25023-001.html}
}

@article{roedigerPowerTestingMemory2006,
  title = {The {{Power}} of {{Testing Memory}}: {{Basic Research}} and {{Implications}} for {{Educational Practice}}},
  shorttitle = {The {{Power}} of {{Testing Memory}}},
  author = {Roediger, Henry L. and Karpicke, Jeffrey D.},
  year = {2006},
  month = sep,
  journal = {Perspect Psychol Sci},
  volume = {1},
  number = {3},
  pages = {181--210},
  issn = {1745-6916, 1745-6924},
  doi = {10.1111/j.1745-6916.2006.00012.x},
  abstract = {A powerful way of improving one's memory for material is to be tested on that material. Tests enhance later retention more than additional study of the material, even when tests are given without feedback. This surprising phenomenon is called the testing effect, and although it has been studied by cognitive psychologists sporadically over the years, today there is a renewed effort to learn why testing is effective and to apply testing in educational settings. In this article, we selectively review laboratory studies that reveal the power of testing in improving retention and then turn to studies that demonstrate the basic effects in educational settings. We also consider the related concepts of dynamic testing and formative assessment as other means of using tests to improve learning. Finally, we consider some negative consequences of testing that may occur in certain circumstances, though these negative effects are often small and do not cancel out the large positive effects of testing. Frequent testing in the classroom may boost educational achievement at all levels of education.},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/S85UEHP7/Roediger and Karpicke - 2006 - The Power of Testing Memory Basic Research and Im.pdf}
}

@article{roedigerRelativityRememberingWhy2008,
  title = {Relativity of {{Remembering}}: {{Why}} the {{Laws}} of {{Memory Vanished}}},
  shorttitle = {Relativity of {{Remembering}}},
  author = {Roediger, Henry L.},
  year = {2008},
  month = jan,
  journal = {Annu. Rev. Psychol.},
  volume = {59},
  number = {1},
  pages = {225--254},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev.psych.57.102904.190139},
  abstract = {For 120 years, cognitive psychologists have sought general laws of learning and memory. In this review I conclude that none has stood the test of time. No empirical law withstands manipulation across the four sets of factors that Jenkins (1979) identified as critical to memory experiments: types of subjects, kinds of events to be remembered, manipulation of encoding conditions, and variations in test conditions. Another factor affecting many phenomena is whether a manipulation of conditions occurs in randomized, within-subjects designs rather than between-subjects (or within-subject, blocked) designs. The fact that simple laws do not hold reveals the complex, interactive nature of memory phenomena. Nonetheless, the science of memory is robust, with most findings easily replicated under the same conditions as originally used, but when other variables are manipulated, effects may disappear or reverse. These same points are probably true of psychological research in most, if not all, domains.},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/ZMDYZLFG/Roediger, III - 2008 - Relativity of Remembering Why the Laws of Memory .pdf}
}

@article{roedigerTestEnhancedLearningTaking2006,
  ids = {roedigerTestenhancedLearningTaking2006},
  title = {Test-{{Enhanced Learning}}: {{Taking Memory Tests Improves Long}}-{{Term Retention}}},
  shorttitle = {Test-{{Enhanced Learning}}},
  author = {Roediger, Henry L. and Karpicke, Jeffrey D.},
  year = {2006},
  month = mar,
  journal = {Psychol Sci},
  volume = {17},
  number = {3},
  pages = {249--255},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2006.01693.x},
  abstract = {Taking a memory test not only assesses what one knows, but also enhances later retention, a phenomenon known as the testing effect. We studied this effect with educationally relevant materials and investigated whether testing facilitates learning only because tests offer an opportunity to restudy material. In two experiments, students studied prose passages and took one or three immediate free-recall tests, without feedback, or restudied the material the same number of times as the students who received tests. Students then took a final retention test 5 min, 2 days, or 1 week later. When the final test was given after 5 min, repeated studying improved recall relative to repeated testing. However, on the delayed tests, prior testing produced substantially greater retention than studying, even though repeated studying increased students' confidence in their ability to remember the material. Testing is a powerful means of improving learning, not just assessing it.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/Matthew/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Roediger et al_2006_Test-enhanced learning.pdf;/Users/mattshu/Zotero/storage/QCK9BIVL/test-enhanced-learning-2.html}
}

@inproceedings{ruanQuizBotDialoguebasedAdaptive2019,
  title = {{{QuizBot}}: {{A Dialogue}}-Based {{Adaptive Learning System}} for {{Factual Knowledge}}},
  shorttitle = {{{QuizBot}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ruan, Sherry and Jiang, Liwei and Xu, Justin and Tham, Bryce Joe-Kun and Qiu, Zhengneng and Zhu, Yeshuang and Murnane, Elizabeth L. and Brunskill, Emma and Landay, James A.},
  year = {2019},
  month = may,
  pages = {1--13},
  publisher = {{ACM}},
  address = {{Glasgow Scotland Uk}},
  doi = {10.1145/3290605.3300587},
  abstract = {Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20\% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with; but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings.},
  isbn = {978-1-4503-5970-2},
  language = {en},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Ruan et al_2019_QuizBot.pdf}
}

@article{rubinOneHundredYears1996,
  title = {One Hundred Years of Forgetting: {{A}} Quantitative Description of Retention},
  shorttitle = {One Hundred Years of Forgetting},
  author = {Rubin, David C. and Wenzel, Amy E.},
  year = {1996},
  journal = {Psychological Review},
  volume = {103},
  number = {4},
  pages = {734--760},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/0033-295X.103.4.734},
  abstract = {A sample of 210 published data sets were assembled that (a) plotted amount remembered versus time, (b) had 5 or more points, and (c) were smooth enough to fit at least 1 of the functions tested with a correlation coefficient of .90 or greater. Each was fit to 105 different 2-parameter functions. The best fits were to the logarithmic function, the power function, the exponential in the square root of time, and the hyperbola in the square root of time. It is difficult to distinguish among these 4 functions with the available data, but the same set of 4 functions fit most data sets, with autobiographical memory being the exception. Theoretical motivations for the best fitting functions are offered. The methodological problems of evaluating functions and the advantages of searching existing data for regularities before formulating theories are considered. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Data Sets,Retention},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Rubin_Wenzel_1996_One hundred years of forgetting.pdf;/Users/mattshu/Zotero/storage/SIU6FDLG/1996-06397-006.html}
}

@article{rubinPreciseTimeCourse1999,
  title = {The Precise Time Course of Retention},
  author = {Rubin, David C. and Hinton, Sean and Wenzel, Amy},
  year = {1999},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {25},
  number = {5},
  pages = {1161--1176},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/0278-7393.25.5.1161},
  abstract = {Fits of retention data were examined from 5 conditions: 3 types of cued recall, an old\textendash new recognition task, and a remember\textendash know recognition task. In each condition, 100 participants had either 18 recall or 27 recognition trials at each of 10 delays between 0 and 99 intervening items, providing the first data obtained in experimental psychology that were precise enough to distinguish clearly among simple functions. None of the 105 2-parameter functions tested produced adequate fits to the data. The function y\hspace{0.6em}=\hspace{0.6em}a{$_1$}e\textendash t/1.15\hspace{0.6em}+\hspace{0.6em}a{$_2$}e\textendash t/T2\hspace{0.6em}+\hspace{0.6em}a{$_3$} fit each of the 5 retention conditions. The T{$_2$} parameter in this equation equaled 28 for the 3 recall conditions and the remember\textendash know recognition condition and 13 for the old\textendash new recognition condition. Individuals' recall data fit the same function with parameters varying with gender and scholastic aptitude scores. Reaction times support the claim that the a{$_1$}e\textendash t/1.15 term describes working memory, and the remaining 2 terms describe long-term memory. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Empirical Methods,Mathematical Modeling,Memory,Recognition (Learning),Retention},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Rubin et al_1999_The precise time course of retention2.pdf;/Users/mattshu/Zotero/storage/FQSTY2ZF/1999-03993-004.html}
}

@article{saletinNocturnalMnemonicsSleep2012,
  title = {Nocturnal {{Mnemonics}}: {{Sleep}} and {{Hippocampal Memory Processing}}},
  shorttitle = {Nocturnal {{Mnemonics}}},
  author = {Saletin, Jared M. and Walker, Matthew P.},
  year = {2012},
  month = may,
  journal = {Front Neurol},
  volume = {3},
  issn = {1664-2295},
  doi = {10.3389/fneur.2012.00059},
  abstract = {As critical as waking brain function is to learning and memory, an established literature now describes an equally important yet complementary role for sleep in information processing. This overview examines the specific contribution of sleep to human hippocampal memory processing; both the detriments caused by a lack of sleep, and conversely, the proactive benefits that develop following the presence of sleep. First, a role for sleep before learning is discussed, preparing the hippocampus for initial memory encoding. Second, a role for sleep after learning is considered, modulating the post-encoding consolidation of hippocampal-dependent memory. Third, a model is outlined in which these encoding and consolidation operations are symbiotically accomplished, associated with specific NREM sleep physiological oscillations. As a result, the optimal network outcome is achieved: increasing hippocampal independence and hence overnight consolidation, while restoring next-day sparse hippocampal encoding capacity for renewed learning ability upon awakening. Finally, emerging evidence is considered suggesting that, unlike previous conceptions, sleep does not universally consolidate all information. Instead, and based on explicit as well as saliency cues during initial encoding, sleep executes the discriminatory offline consolidation only of select information. Consequently, sleep promotes the targeted strengthening of some memories while actively forgetting others; a proposal with significant theoretical and clinical ramifications.},
  pmcid = {PMC3340569},
  pmid = {22557988},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Saletin_Walker_2012_Nocturnal Mnemonics.pdf}
}

@article{sargissonFORMFORGETTINGFUNCTION2003,
  title = {{{ON THE FORM OF THE FORGETTING FUNCTION}}: {{THE EFFECTS OF ARITHMETIC AND LOGARITHMIC DISTRIBUTIONS OF DELAYS}}},
  shorttitle = {{{ON THE FORM OF THE FORGETTING FUNCTION}}},
  author = {Sargisson, Rebecca J. and White, K. Geoffrey},
  year = {2003},
  month = nov,
  journal = {Journal of the Experimental Analysis of Behavior},
  volume = {80},
  number = {3},
  pages = {295--309},
  issn = {00225002},
  doi = {10.1901/jeab.2003.80-295},
  abstract = {Forgetting functions with 18 delay intervals were generated for delayed matching-to-sample performance in pigeons. Delay interval variation was achieved by arranging five different sets of five delays across daily sessions. In different conditions, the delays were distributed in arithmetic or logarithmic series. There was no convincing evidence for different effects on discriminability of the distributions of different delays. The mean data were better fitted by some mathematical functions than by others, but the best-fitting functions depended on the distribution of delays. In further conditions with a fixed set of five delays, discriminability was higher with a logarithmic distribution of delays than with an arithmetic distribution. This result is consistent with the treatment of the forgetting function in terms of generalization decrement.},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/UYIUXL49/Sargisson and White - 2003 - ON THE FORM OF THE FORGETTING FUNCTION THE EFFECT.pdf}
}

@article{schimankeEnhancingMobileLearning,
  title = {Enhancing {{Mobile Learning Games}} with {{Spaced}}-{{Repetition}} and {{Content}}-{{Selection Algorithms}}},
  author = {Schimanke, Florian and Mertens, Robert and Vornberger, Oliver and Hillebrand, Jonathan},
  pages = {10},
  abstract = {Spaced repetition is an algorithmic strategy for selecting learning content based on the learner's previous interaction with the mentioned content. Presentation intervals are longer for items presented more often and already learned. But even these items are presented in order to avoid forgetting them over time. Hence spaced repetition is an ideal tool for avoiding forgetting of once learned content. Integrating this content selection strategy in (mobile) learning games does not only foster learning in a more efficient way, it also keeps learners/players more motivated as their performance increases over time. This paper discusses strategies for adding spaced repetition content selection to existing games to combine already successful learning games with this promising content selection strategy.},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Schimanke et al_Enhancing Mobile Learning Games with Spaced-Repetition and Content-Selection.pdf}
}

@inproceedings{settlesTrainableSpacedRepetition2016,
  title = {A {{Trainable Spaced Repetition Model}} for {{Language Learning}}},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Settles, Burr and Meeder, Brendan},
  year = {2016},
  month = aug,
  pages = {1848--1858},
  publisher = {{Association for Computational Linguistics}},
  address = {{Berlin, Germany}},
  doi = {10.18653/v1/P16-1174},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Settles_Meeder_2016_A Trainable Spaced Repetition Model for Language Learning.pdf}
}

@misc{SevenYearsSpaced,
  title = {Seven {{Years}} of {{Spaced Repetition Software}} in the {{Classroom}} - {{LessWrong}}},
  abstract = {DESCRIPTION This is a reflective essay and report on my experiences using Spaced Repetition  Software (SRS) in an American high school classroom. It follows my 2015 and 2016  posts on the same topic. Because I value concise summaries in non-fiction, I provide one immediately below. However, I also believe in the power of narrative, in carefully unfolding a story so as to maximize reader engagement and impact. As I have applied such narrative considerations in writing this post, I consider the following summary to be a spoiler. I'll let you decide what to do with that information. SUMMARY (SPOILERS) My earlier push for classroom SRS solutions was driven by a belief I came to see as fallacious: that forgetting is the undoing of learning. This epistemic shift drove me to abandon designs for a custom app that would have integrated whole-class and individual SRS functions. While I still see value in classroom use of Spaced Repetition Software, especially in basic language acquisition, I have greatly reduced its use in my own classes. In my third year of experiments (2016-17), I used a windfall of classroom computers to give students supervised time to independently study using an SRS app with individual profiles. I found longer-term average performance to be slightly worse than under the whole-class group study model, though students of high intelligence and motivation saw slight improvements. INTRO AND RESPONSE TO PIOTR WO\'ZNIAK I have recently received a number of requests to revisit the topic of classroom SRS after years of silence on the subject. Understandably, the term ``postmortem'' has come up more than once. Did I hit a dead end? Do I still use it? Also, I was informed that SRS founding father Piotr Wo\'zniak recently added a page to his SuperMemo wiki in which he quoted me at length and claimed that SRS doesn't belong in the classroom. Well, I don't have much in the way of rebuttal, because Wo\'zniak's main goal with the page seems to be to use my experience a},
  howpublished = {https://www.lesswrong.com/posts/F6ZTtBXn2cFLmWPdM/seven-years-of-spaced-repetition-software-in-the-classroom-1},
  file = {/Users/mattshu/Zotero/storage/LMNHNDM9/seven-years-of-spaced-repetition-software-in-the-classroom-1.html}
}

@article{smolenRightTimeLearn2016,
  title = {The Right Time to Learn: Mechanisms and Optimization of Spaced Learning},
  shorttitle = {The Right Time to Learn},
  author = {Smolen, Paul and Zhang, Yili and Byrne, John H.},
  year = {2016},
  month = feb,
  journal = {Nat Rev Neurosci},
  volume = {17},
  number = {2},
  pages = {77--88},
  issn = {1471-003X},
  doi = {10.1038/nrn.2015.18},
  abstract = {For many types of learning, spaced training, which involves repeated long inter-trial intervals, leads to more robust memory formation than does massed training, which involves short or no intervals. Several cognitive theories have been proposed to explain this superiority, but only recently have data begun to delineate the underlying cellular and molecular mechanisms of spaced training, and we review these theories and data here. Computational models of the implicated signalling cascades have predicted that spaced training with irregular inter-trial intervals can enhance learning. This strategy of using models to predict optimal spaced training protocols, combined with pharmacotherapy, suggests novel ways to rescue impaired synaptic plasticity and learning.},
  pmcid = {PMC5126970},
  pmid = {26806627},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Smolen et al_2016_The right time to learn.pdf}
}

@article{stahlPlayItAgain2010,
  title = {Play It {{Again}}: {{The Master Psychopharmacology Program}} as an {{Example}} of {{Interval Learning}} in {{Bite}}-{{Sized Portions}}},
  shorttitle = {Play It {{Again}}},
  author = {Stahl, Stephen M. and Davis, Richard L. and Kim, Dennis H. and Lowe, Nicole Gellings and Carlson, Richard E. and Fountain, Karen and Grady, Meghan M.},
  year = {2010},
  month = aug,
  journal = {CNS Spectr},
  volume = {15},
  number = {8},
  pages = {491--504},
  issn = {1092-8529},
  doi = {10.1017/s1092852900000444},
  language = {eng},
  pmid = {20703196},
  keywords = {Humans,Learning,Psychopharmacology},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Stahl et al_2010_Play it Again.pdf}
}

@article{stickgoldSleepdependentMemoryConsolidation2007,
  title = {Sleep-Dependent Memory Consolidation and Reconsolidation},
  author = {Stickgold, Robert and Walker, Matthew P.},
  year = {2007},
  month = jun,
  journal = {Sleep Medicine},
  series = {Advances in {{Sleep Medicine}}},
  volume = {8},
  number = {4},
  pages = {331--343},
  issn = {1389-9457},
  doi = {10.1016/j.sleep.2007.03.011},
  abstract = {Molecular, cellular, and systems-level processes convert initial, labile memory representations into more permanent ones, available for continued reactivation and recall over extended periods of time. These processes of memory consolidation and reconsolidation are not all-or-none phenomena, but rather a continuing series of biological adjustments that enhance both the efficiency and utility of stored memories over time. In this chapter, we review the role of sleep in supporting these disparate but related processes.},
  language = {en},
  keywords = {Consolidation,Learning,Memory,Motor sequence learning,Reconsolidation,REM,Sleep,Slow-wave sleep,Visual discrimination},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Stickgold_Walker_2007_Sleep-dependent memory consolidation and reconsolidation.pdf}
}

@book{streeterMixtureModelingIndividual2015,
  title = {Mixture {{Modeling}} of {{Individual Learning Curves}}},
  author = {Streeter, Matthew},
  year = {2015},
  month = jun,
  journal = {International Educational Data Mining Society},
  publisher = {{International Educational Data Mining Society}},
  abstract = {We show that student learning can be accurately modeled using a mixture of learning curves, each of which specifies error probability as a function of time. This approach generalizes Knowledge Tracing [7], which can be viewed as a mixture model in which the learning curves are step functions. We show that this generality yields order-of-magnitude improvements in prediction accuracy on real data. Furthermore, examination of the learning curves provides actionable insights into how different segments of the student population are learning. To make our mixture model more expressive, we allow the learning curves to be defined by generalized linear models with arbitrary features. This approach generalizes Additive Factor Models [4] and Performance Factors Analysis [16], and outperforms them on a large, real world dataset. [For complete proceedings, see ED560503.]},
  language = {en},
  keywords = {_tablet,Accuracy,Educational Technology,Error Patterns,Intelligent Tutoring Systems,Knowledge Level,Learning Processes,Models,Prediction,Probability,Skill Development,Statistical Analysis},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Streeter_2015_Mixture Modeling of Individual Learning Curves.pdf;/Users/mattshu/Zotero/storage/RFC48VGC/eric.ed.gov.html}
}

@article{sullivanGettingGoldStandard2011,
  title = {Getting {{Off}} the ``{{Gold Standard}}'': {{Randomized Controlled Trials}} and {{Education Research}}},
  shorttitle = {Getting {{Off}} the ``{{Gold Standard}}''},
  author = {Sullivan, Gail M},
  year = {2011},
  month = sep,
  journal = {Journal of Graduate Medical Education},
  volume = {3},
  number = {3},
  pages = {285--289},
  publisher = {{Accreditation Council for Graduate Medical Education}},
  issn = {1949-8349},
  doi = {10.4300/JGME-D-11-00147.1},
  keywords = {_tablet,to read},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Sullivan_2011_Getting Off the â€œGold Standardâ€.pdf;/Users/mattshu/Zotero/storage/2ZHD2RGG/JGME-D-11-00147.html}
}

@misc{SuperMemoLearnLanguages,
  title = {{{SuperMemo}} - Learn Languages Effectively},
  abstract = {Learn a new language at your convenience and remember it for good! Just submit to the SuperMemo algorithm.},
  howpublished = {https://www.supermemo.com/en},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/5ADEYU88/en.html}
}

@article{tabibianEnhancingHumanLearning2019,
  ids = {tabibianEnhancingHumanLearning},
  title = {Enhancing Human Learning via Spaced Repetition Optimization},
  author = {Tabibian, Behzad and Upadhyay, Utkarsh and De, Abir and Zarezade, Ali and Sch{\"o}lkopf, Bernhard and {Gomez-Rodriguez}, Manuel},
  year = {2019},
  month = mar,
  journal = {PNAS},
  volume = {116},
  number = {10},
  pages = {3988--3993},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1815156116},
  abstract = {Spaced repetition is a technique for efficient memorization which uses repeated review of content following a schedule determined by a spaced repetition algorithm to improve long-term retention. However, current spaced repetition algorithms are simple rule-based heuristics with a few hard-coded parameters. Here, we introduce a flexible representation of spaced repetition using the framework of marked temporal point processes and then address the design of spaced repetition algorithms with provable guarantees as an optimal control problem for stochastic differential equations with jumps. For two well-known human memory models, we show that, if the learner aims to maximize recall probability of the content to be learned subject to a cost on the reviewing frequency, the optimal reviewing schedule is given by the recall probability itself. As a result, we can then develop a simple, scalable online spaced repetition algorithm, MEMORIZE, to determine the optimal reviewing times. We perform a large-scale natural experiment using data from Duolingo, a popular language-learning online platform, and show that learners who follow a reviewing schedule determined by our algorithm memorize more effectively than learners who follow alternative schedules determined by several heuristics.},
  chapter = {Physical Sciences},
  copyright = {Copyright \textcopyright{} 2019 the Author(s). Published by PNAS.. http://creativecommons.org/licenses/by/4.0/This open access article is distributed under Creative Commons Attribution License 4.0 (CC BY).},
  language = {en},
  pmid = {30670661},
  keywords = {human learning,marked temporal point processes,memorization,spaced repetition,stochastic optimal control},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Tabibian et al_2019_Enhancing human learning via spaced repetition optimization.pdf;/Users/mattshu/Zotero/storage/8TWPH8DL/3988.html}
}

@misc{tsaiRepetitionsCrossplatformSpaced,
  title = {Repetitions - {{Cross}}-Platform Spaced Repetition Flashcards},
  author = {Tsai, Paul},
  abstract = {Repetitions is a cross-platform spaced repetition system (SRS), an intelligent flashcard application that makes learning and memorization easy.},
  howpublished = {http://www.repetitionsapp.com},
  language = {en},
  file = {/Users/mattshu/Zotero/storage/RDZUVWQ6/www.repetitionsapp.com.html}
}

@misc{TypesScientificPaper,
  title = {Types of {{Scientific Paper}}},
  journal = {xkcd},
  howpublished = {https://xkcd.com/2456/},
  file = {/Users/mattshu/Zotero/storage/I4M7QKVU/2456.html}
}

@article{underwoodInterferenceForgetting1957,
  title = {Interference and Forgetting},
  author = {Underwood, Benton J.},
  year = {1957},
  journal = {Psychological Review},
  volume = {64},
  number = {1},
  pages = {49--60},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/h0044616},
  abstract = {"This paper deals with issues in the foregetting of rotelearned materials. An analysis of the current evidence suggests that the classical Ebbinghaus curve of forgetting is primarily a function of interference from materials learned previously in the laboratory. When this source of interference is removed, forgetting decreases from about 75 per cent over 24 hours to about 25 per cent. This latter figure can be reduced by a least 10 per cent by other methodological considerations, leaving 15 per cent as an estimate of the forgetting over 24 hours. This estimate will vary somewhat as a function of intratask similarity, distributed practice, and with very low meaningful material. But the overall evidence suggests that similarity with other material and situational similarity are by far the most critical factors in forgetting. Such evidence is consonant with a general interference theory, although the details of such a theory were not presented here." (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Forgetting,Interference (Learning),Retroactive Inhibition,Rote Learning},
  file = {/Users/mattshu/Zotero/storage/YI4WABSP/1958-00251-001.html}
}

@article{upadhyayLargescaleRandomizedExperiment2020,
  title = {Large-Scale Randomized Experiment Reveals Machine Learning Helps People Learn and Remember More Effectively},
  author = {Upadhyay, Utkarsh and Lancashire, Graham and Moser, Christoph and {Gomez-Rodriguez}, Manuel},
  year = {2020},
  month = oct,
  journal = {arXiv:2010.04430 [cs, stat]},
  eprint = {2010.04430},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Machine learning has typically focused on developing models and algorithms that would ultimately replace humans at tasks where intelligence is required. In this work, rather than replacing humans, we focus on unveiling the potential of machine learning to improve how people learn and remember factual material. To this end, we perform a large-scale randomized controlled trial with thousands of learners from a popular learning app in the area of mobility. After controlling for the length and frequency of study, we find that learners whose study sessions are optimized using machine learning remember the content over \$\textbackslash sim\$67\% longer than those whose study sessions are generated using two alternative heuristics. Our randomized controlled trial also reveals that the learners whose study sessions are optimized using machine learning are \$\textbackslash sim\$50\% more likely to return to the app within 4-7 days.},
  archiveprefix = {arXiv},
  keywords = {_tablet,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Upadhyay et al_2020_Large-scale randomized experiment reveals machine learning helps people learn.pdf;/Users/mattshu/Zotero/storage/AX6HWMQS/2010.html}
}

@book{vygotskyMindSocietyDevelopment1980,
  title = {Mind in {{Society}}: {{The Development}} of {{Higher Psychological Processes}}},
  shorttitle = {Mind in {{Society}}},
  author = {Vygotsky, L. S.},
  year = {1980},
  month = oct,
  publisher = {{Harvard University Press}},
  abstract = {The great Russian psychologist L. S. Vygotsky has long been recognized as a pioneer in developmental psychology. But his theory of development has never been well understood in the West. Mind in Society corrects much of this misunderstanding. Carefully edited by a group of outstanding Vygotsky scholars, the book presents a unique selection of Vygotsky's important essays.},
  googlebooks = {Irq913lEZ1QC},
  isbn = {978-0-674-07668-6},
  language = {en},
  keywords = {Psychology / General}
}

@article{wilsonEightyFivePercent2019,
  title = {The {{Eighty Five Percent Rule}} for Optimal Learning},
  author = {Wilson, Robert C. and Shenhav, Amitai and Straccia, Mark and Cohen, Jonathan D.},
  year = {2019},
  month = nov,
  journal = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {4646},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-12552-4},
  abstract = {Researchers and educators have long wrestled with the question of how best to teach their clients be they humans, non-human animals or machines. Here, we examine the role of a single variable, the difficulty of training, on the rate of learning. In many situations we find that there is a sweet spot in which training is neither too easy nor too hard, and where learning progresses most quickly. We derive conditions for this sweet spot for a broad class of learning algorithms in the context of binary classification tasks. For all of these stochastic gradient-descent based learning algorithms, we find that the optimal error rate for training is around 15.87\% or, conversely, that the optimal training accuracy is about 85\%. We demonstrate the efficacy of this `Eighty Five Percent Rule' for artificial neural networks used in AI and biologically plausible neural networks thought to describe animal learning.},
  copyright = {2019 The Author(s)},
  language = {en},
  keywords = {_tablet},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Wilson et al_2019_The Eighty Five Percent Rule for optimal learning.pdf;/Users/mattshu/Zotero/storage/6SXHL4SP/s41467-019-12552-4.html}
}

@article{wixtedWickelgrenPowerLaw2007,
  title = {The {{Wickelgren Power Law}} and the {{Ebbinghaus Savings Function}}},
  author = {Wixted, John T. and Carpenter, Shana K.},
  year = {2007},
  month = feb,
  journal = {Psychol Sci},
  volume = {18},
  number = {2},
  pages = {133--134},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2007.01862.x},
  language = {en},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Wixted_Carpenter_2007_The Wickelgren Power Law and the Ebbinghaus Savings Function.pdf}
}

@article{wozniakOptimizationRepetitionSpacing1994,
  ids = {wozniakOptimizationRepetitionSpacing1993},
  title = {Optimization of Repetition Spacing in the Practice of Learning},
  author = {Wo{\'z}niak, Piotr and Gorzela{\'n}czyk, Edward J},
  year = {1994},
  journal = {Acta Neurobiol Exp (Wars)},
  volume = {54},
  number = {1},
  pages = {59--62},
  issn = {0065-1400},
  abstract = {A universal formula for computing inter-repetition intervals in paired-associate learning has been determined for the knowledge retention level of 95\%. It is claimed that the formula could be used in the practice of learning for a wide range of subjects, regardless individual learner's capacity.},
  language = {eng},
  pmid = {8023714},
  keywords = {_tablet,Humans,Models; Neurological,Paired-Associate Learning,Retention; Psychology,Time Factors},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Wozniak_Gorzelanczyk_1993_Optimization of repetition spacing in the practice of learning.pdf}
}

@misc{wozniakTheoreticalAspectsSpaced,
  title = {Theoretical Aspects of Spaced Repetition in Learning},
  author = {Wozniak, Piotr},
  howpublished = {http://super-memory.com/articles/theory.htm},
  file = {/Users/mattshu/Zotero/storage/DFVILGME/theory.html}
}

@article{wozniakTwoComponentsLongterm1995,
  title = {Two Components of Long-Term Memory},
  author = {Wo{\'z}niak, P. A. and Gorzela{\'n}czyk, E. J. and Murakowski, J. A.},
  year = {1995},
  journal = {Acta Neurobiol Exp (Wars)},
  volume = {55},
  number = {4},
  pages = {301--305},
  issn = {0065-1400},
  abstract = {The existence of two independent components of long-term memory has been demonstrated by the authors. The evidence has been derived from the authors' findings related to the optimum spacing of repetitions in paired-associate learning. The two components are sufficient to explain the optimum spacing of repetitions as well as the spacing effect. Although the molecular counterparts of the two components of memory are not known, the authors provide a collection of guidelines that might facilitate identification of such counterparts.},
  language = {eng},
  pmid = {8713361},
  keywords = {Humans,Memory},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/WoÅºniak et al_1995_Two components of long-term memory.pdf}
}

@inproceedings{yujianzhouPracticalStudentModel1999,
  title = {A Practical Student Model in an Intelligent Tutoring System},
  booktitle = {Proceedings 11th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}}},
  author = {{Yujian Zhou} and Evens, M. W.},
  year = {1999},
  month = nov,
  pages = {13--18},
  issn = {1082-3409},
  doi = {10.1109/TAI.1999.809759},
  abstract = {We consider two questions related to student modeling in an intelligent tutoring system: 1) what kind of student model should we build when we design a new system; and 2) should we divide the student model into different components depending on the information involved. We consider these two questions in the context of a conversational intelligent tutoring system, CIRCSIM-Tutor. We first analyze the range of decisions that the system needs to make and define the information needed to support these decisions. We then describe four distinct models that provide different aspects of this information, taking into consideration the nature of the domain and the constraints provided by the tutoring system. Finally, we briefly discuss our experiments with enhancing the student model in CIRCSIM-Tutor and some general problems regarding building and evaluating different student models.},
  keywords = {CIRCSIM-Tutor,Context modeling,conversational intelligent tutoring system,Data mining,Decision making,Information analysis,Intelligent systems,intelligent tutoring system,intelligent tutoring systems,Medical control systems,Negative feedback,Pressure control,Problem-solving,student model,student modeling,user modelling,World Wide Web},
  file = {/Users/mattshu/Library/Mobile Documents/com~apple~CloudDocs/Stuff/Media/Zotero/Yujian Zhou_Evens_1999_A practical student model in an intelligent tutoring system.pdf;/Users/mattshu/Zotero/storage/PPKAY8TI/809759.html}
}


