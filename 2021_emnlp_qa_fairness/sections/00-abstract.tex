
The goal of question answering (\abr{qa}) is to answer \emph{any} question.
However, major \abr{qa} datasets have skewed distributions over gender, profession, and nationality.
Despite that skew, model accuracy analysis reveals little evidence that accuracy is lower for people based on gender or nationality; instead, there is more variation on professions (question topic).
But \abr{qa}'s lack of representation could itself hide evidence of bias, necessitating \abr{qa} datasets that better represent global diversity.

