\section{Conclusion}

This paper explores users' perceptions, experience, and behavior with
easy-to-validate controls that vary in terms of control, particularly
how well user input was \textit{adhered to} and whether other changes
occurred during model updates (\textit{instability}), as well as how
long updates took and model quality.
We found that: (1) participants
noticed---and often disliked---when their input was not adhered to,
particularly for the easiest-to-validate refinements; (2) participants
were polarized by instability, both in whether they noticed it and how
they reacted to it: some participants liked it while others did not;
(3) participants thought all the systems were slow but good:
participants were satisfied with the final models they generated and
thought they showed improvement over their starting points; (4) user
experience did not differ between the systems: participants on average
were confident in their input, trusted the models to update
effectively, and thought the task was easy, but some participants were
frustrated, particularly by slow updates.
