We explore predictability and control in interactive systems where controls are easy to validate.
Human-in-the-loop techniques allow users to guide unsupervised
algorithms by exposing and supporting interaction with underlying
model representations, increasing transparency and promising fine-grained control.
However, these models must balance user input and the underlying
data, meaning they sometimes update slowly, poorly, or
unpredictably---either by not incorporating user input as expected
(\textit{adherence}) or by making other unexpected changes
(\textit{instability}).
While prior work exposes model internals and supports user feedback,
less attention has been paid to users' reactions when transparent
models limit control.
Focusing on interactive topic models, we explore user perceptions of control using a study
where 100 participants organize documents with one of three
distinct topic modeling approaches.
These approaches incorporate input differently, resulting
in varied adherence, stability, update speeds, and model quality.
Participants disliked slow updates most, followed by lack of
adherence.
Instability was polarizing: some participants liked it when it
surfaced interesting information, while others did not.
Across modeling approaches, participants differed only in whether
they noticed adherence.
