% abstract

\begin{abstract}

  Cross-lingual word embeddings~(\abr{clwe}) underlie many
  multilingual natural language processing systems, often through
  orthogonal transformations of pre-trained monolingual embeddings.
  %
  However, orthogonal mapping only works on language pairs
  whose embeddings are naturally isomorphic.
  %
  For non-isomorphic pairs, our method (\name{}) transforms
  monolingual embeddings to make orthogonal alignment easier by
  simultaneously enforcing that (1)~individual word vectors are unit
  length, and (2)~each language's average vector is zero.
  %
  \name{} consistently improves word translation accuracy of three
  \abr{clwe} methods, with the largest improvement observed on English-Japanese
  (from 2\% to 44\% test accuracy).

\end{abstract}
