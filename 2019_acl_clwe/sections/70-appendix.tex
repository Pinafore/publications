\section{Proof for Theorem \ref{thm:converge}}\label{sec:proof}
Our convergence analysis is based on a recent result on alternating
non-convex projections. Theorem 1 in the work of ~\citet{zhu2018convergence}
states that the convergence of alternating projection holds even if the
constraint sets are non-convex, as long as the two constraint sets satisfy the following
assumption:

\begin{assumption}\label{asp:ap}
Let $ \mathbb{X}$ and $\mathbb{Y}$ be any two closed semi-algebraic sets, and let $\left\lbrace \left( \vect{x}_k, \vect{y}_k \right)  \right\rbrace $ be the sequence of iterates generated by the alternating projection method (e.g., \name{}). Assume the sequence $\left\lbrace \left( \vect{x}_k, \vect{y}_k \right)  \right\rbrace $ is bounded and the sets $ \mathbb{X}$ and $\mathbb{Y}$ obey the following properties: 
\begin{enumerate}
\item[(i)]  three-point property of $\mathbb{Y}$:  there exists a nonnegative function $\delta_{\alpha}: \mathbb{Y} \times \mathbb{Y} \rightarrow \mathbb{R}$ with $\alpha > 0$ such that for any $k \geq 1$, we have
\begin{equation*}
  \delta_{\alpha} \left( \vect{y}_k, \vect{y}_{k-1} \right) \geq \alpha  \|\vect{y}_k- \vect{y}_{k-1}\|_2
\end{equation*}
and 
\begin{equation*}
  \delta_{\alpha} \left(  \vect{y}_{k-1}, \vect{y}_k \right) + \| \vect{x}_k-\vect{y}_k \|_2^2 \\
  \leq  \| \vect{x}_k-\vect{y}_{k-1} \|_2^2, %& \\  \forall k \geq 1 &
\end{equation*}
\item[(ii)]  local contraction property of $ \mathbb{X}$:  there exist $\epsilon>0$ and $\beta>0$ such that when $\|\vect{y}_k-\vect{y}_{k-1}\|_2\leq \epsilon$, we have 
\begin{align*}
  \| \vect{x}_{k+1}-\vect{x}_k \|_2 & = \| \mathcal{P}_{ \mathbb{X}} (\vect{y}_k )- \mathcal{P}_{ \mathbb{X}} (\vect{y}_{k-1} )  \|_2 \\
  & \leq \beta \|  \vect{y}_k-\vect{y}_{k-1}  \|_2 
\end{align*}
where $\mathcal{P}_{ \mathbb{X}}$ is the projection onto ${ \mathbb{X}}$. 
\end{enumerate}
\end{assumption}

\citet{zhu2018convergence} only consider sets of vectors, but our constraint
are sets of matrices.  For ease of exposition, we treat every embedding
matrix $\vect{X} \in \mathbb{R}^{d \times n}$ as a vector by concatenating
the column vectors: $\vect{X} = \lbrack \vect{x}_1, \vect{x}_2, \cdots,
\vect{x}_n \rbrack$.  The $l^2$-norm of the concatenated vector $\| \vect{X}
\|_2$ is equivalent to the Frobenius norm of the original matrix $\| \vect{X}
\|_F$.

The two operations in \name{}, Equation~\eqref{eq:renorm} and \eqref{eq:center},
are projections onto two constraint sets, unit-length set $\mathbb{Y} =
\left\lbrace \vect{X} \in \mathbb{R}^{d \times n} : \forall i,
\|\vect{x}_i\|_2=1 \right\rbrace$ and zero-mean set $\mathbb{X} =
\left\lbrace \vect{X}\in\mathbb{R}^{d \times n} : \sum_{i=1}^n \vect{x}_i=\vect{0}
\right\rbrace$.  To prove convergence of \name{}, we show that $\mathbb{Y}$
satisfies the three-point property, and $\mathbb{X}$ satisfies the local
contraction property.

\paragraph{Three-point property of $\mathbb{Y}$.}
For any $\vect{Y}' \in \mathbb{Y}$ and $\vect{X} \in \mathbb{R}^{n\times d}$,
let $\vect{Y}$ be the projection of $\vect{X}$ onto the constraint set
$\mathbb{Y}$ with Equation~\eqref{eq:renorm}.
The columns of $\vect{Y}$ and $\vect{Y'}$ have the same length, so we have
\begin{align}
  &\| \vect{X}-\vect{Y}' \|_2^2-\| \vect{X}-\vect{Y} \|_2^2 \nonumber \\
  & \quad = \sum_{i=1}^n \| \vect{x}_i-\vect{y}'_i \|^2-\| \vect{x}_i-\vect{y}_i \|_2^2 \nonumber\\
  & \quad = \sum_{i=1}^n 2\vect{x}_i^\top\vect{y}_i-2\vect{x}_i^\top\vect{y}'_i.
  \label{eq:rewrite-1}
\end{align}
Since $\vect{Y}$ is the projection of $\vect{X}$ onto the unit-length
set with Equation~\eqref{eq:renorm}; i.e., $\vect{y}_i = \vect{x}_i / \|\vect{x}_i\|_2$,
we can rewrite Equation~\eqref{eq:rewrite-1}.
\begin{align}
  &\| \vect{X}-\vect{Y}' \|_2^2-\| \vect{X}-\vect{Y} \|_2^2 \nonumber\\
  &\quad = \sum_{i=1}^n \|\vect{x}_i\|_2 (2\vect{y}_i^\top\vect{y}_i-2\vect{y}_i^\top\vect{y}'_i). \label{eq:rewrite-2}
\end{align}
All columns of $\vect{Y}$ and $\vect{Y'}$ are unit-length.  Therefore, we can
further rewrite Equation~\eqref{eq:rewrite-2}.
\begin{align*}
  &\| \vect{X}-\vect{Y}' \|_2^2-\| \vect{X}-\vect{Y} \|_2^2\\
  & \quad = \sum_{i=1}^n \| \vect{x}_i \|_2 (2- 2 \vect{y}_i^\top \vect{y}'_i)\\
  & \quad = \sum_{i=1}^n \| \vect{x}_i \|_2 \| \vect{y}_i-\vect{y}'_i \|_2^2.
\end{align*}
Let $l = \min_{i} \left\lbrace \|\vect{x}_i\|_2 \right\rbrace$ be the minimum
length of the columns in $\vect{X}$.  We have the following inequality:
\begin{align*}
  &\| \vect{X}-\vect{Y}' \|_2^2-\| \vect{X}-\vect{Y} \|_2^2\\
  & \quad \geq \sum_{i=1}^n l \| \vect{y}_i-\vect{y}'_i \|_2^2\\
  & \quad = l ||\vect{Y}-\vect{Y}'\|_2^2.
\end{align*}
From our non-zero assumption, the minimum column length $l$ is always positive.
Let $l_k$ be the minimum column length of the embedding matrix
$\vect{X}^{(k)}$ after the $k$-th iteration.  It follows that $\mathbb{Y}$
satisfies the three-point property with $\alpha = \min_{k} \left\lbrace l_k
\right\rbrace$ and $\delta_\alpha (\vect{Y}, \vect{Y}') = \alpha \| \vect{Y}
-\vect{Y}'\|_2^2$.

\paragraph{Local contraction property of $\mathbb{X}$.}
The zero-mean constraint set $\mathbb{X}$ is convex and closed: if two
matrices $\vect{X}$ and $\vect{Y}$ both have zero-mean, their linear
interpolation $\lambda \vect{X} + (1 - \lambda) \vect{Y}$ must also have
zero-mean for any $0 < \lambda < 1$.
Projections onto convex sets in a Hilbert space are
contractive~\cite{browder-67}, and therefore $\mathbb{X}$ satisfies the local
contraction property with any positive $\epsilon$ and $\beta = 1$.

In summary, the two constraint sets that \name{} projects onto satisfy
Assumption~\ref{asp:ap}.  Therefore, \name{} converges following the analysis 
of~\citet{zhu2018convergence}.

\section{Results on All Languages}\label{sec:result_all}

Table~\ref{tab:result_all} shows word translation accuracies on all target
languages.  \name{} improves accuracy on all languages.

\begin{table*}[p]
  \centering
  \setlength{\tabcolsep}{0.1cm}
  \begin{tabular}{lRRRRRRRRR}
    \toprule
    & \multicolumn{3}{c}{Procrustes} & \multicolumn{3}{c}{Procrustes + refine} & \multicolumn{3}{c}{\abr{rcsls}}\\
    \cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
    Target & None & \abr{c+l} & \abr{in} & None & \abr{c+l} & \abr{in} & None & \abr{c+l} & \abr{in}\\
    \midrule
    \abr{af} & 26.3 & 28.3 & \bf{29.7} & 27.7 & 28.7 & \bf{30.4} & 9.3 & 28.6 & \bf{29.3}\\
    \abr{ar} & 36.5 & 37.1 & \bf{37.9} & 36.5 & 37.1 & \bf{37.9} & 18.4 & 40.5 & \bf{41.5}\\
    \abr{bs} & 22.3 & 23.5 & \bf{24.4} & 23.3 & 23.9 & \bf{26.6} & 5.4 & 25.5 & \bf{26.6}\\
    \abr{ca} & 65.9 & 67.6 & \bf{68.9} & 66.5 & 67.6 & \bf{68.9} & 43.0 & 68.9 & \bf{69.5}\\
    \abr{cs} & 54.0 & 54.7 & \bf{55.3} & 54.0 & 54.7 & \bf{55.7} & 29.9 & 57.8 & \bf{58.2}\\
    \abr{da} & 54.0 & 54.9 & \bf{58.4} & 56.8 & 59.3 & \bf{60.9} & 19.2 & 58.3 & \bf{60.5}\\
    \abr{de} & 73.5 & 74.6 & \bf{75.5} & 74.3 & 75.2 & \bf{76.0} & 43.6 & 77.5 & \bf{78.1}\\
    \abr{el} & 44.0 & 44.9 & \bf{47.5} & 44.6 & 45.9 & \bf{47.9} & 14.0 & 47.1 & \bf{48.5}\\
    \abr{es} & 81.4 & 81.3 & \bf{81.5} & 81.9 & 82.1 & \bf{82.5} & 50.5 & 83.6 & \bf{83.9}\\
    \abr{et} & 31.9 & 34.5 & \bf{36.1} & 31.9 & 35.3 & \bf{36.4} & 8.1 & 37.3 & \bf{39.4}\\
    \abr{fa} & 33.1 & 33.7 & \bf{37.3} & 33.1 & 34.1 & \bf{37.3} & 5.9 & 37.5 & \bf{38.3}\\
    \abr{fi} & 47.6 & 48.5 & \bf{50.9} & 47.6 & 50.1 & \bf{51.1} & 20.9 & 52.3 & \bf{53.3}\\
    \abr{fr} & 81.1 & 81.3 & \bf{81.7} & 82.1 & 82.7 & \bf{82.4} & 53.1 & 83.9 & \bf{83.9}\\
    \abr{he} & 40.2 & 43.1 & \bf{43.7} & 40.2 & 43.1 & \bf{43.7} & 13.1 & 49.7 & \bf{50.1}\\
    \abr{hi} & 33.3 & 34.0 & \bf{36.7} & 33.6 & 34.9 & \bf{37.7} & 5.0 & 36.2 & \bf{38.0}\\
    \abr{hr} & 37.0 & 37.8 & \bf{40.2} & 37.6 & 37.8 & \bf{40.2} & 14.5 & 41.1 & \bf{42.6}\\
    \abr{hu} & 51.8 & 54.1 & \bf{55.5} & 53.3 & 54.1 & \bf{56.1} & 11.7 & 57.3 & \bf{58.2}\\
    \abr{id} & 65.6 & 65.7 & \bf{67.9} & 67.7 & 68.4 & \bf{70.3} & 24.8 & 68.9 & \bf{70.0}\\
    \abr{it} & 76.2 & 76.6 & \bf{76.6} & 77.5 & 78.1 & \bf{78.1} & 48.4 & 78.8 & \bf{79.1}\\
    \abr{ja} & 1.7 & 13.1 & \bf{44.3} & 1.7 & 13.1 & \bf{44.3} & 14.6 & 16.1 & \bf{56.3}\\
    \abr{ko} & 31.5 & 32.1 & \bf{33.9} & 31.5 & 32.1 & \bf{33.9} & 6.4 & 37.5 & \bf{37.5}\\
    \abr{lt} & 22.5 & 22.8 & \bf{23.2} & 22.5 & 22.8 & \bf{23.3} & 7.6 & 23.3 & \bf{23.5}\\
    \abr{lv} & 23.6 & 24.9 & \bf{26.1} & 23.6 & 24.9 & \bf{26.1} & 10.1 & 28.3 & \bf{28.7}\\
    \abr{ms} & 44.0 & 45.4 & \bf{48.9} & 46.5 & 48.3 & \bf{51.1} & 19.9 & 49.1 & \bf{50.2}\\
    \abr{nl} & 72.8 & 73.7 & \bf{74.1} & 73.8 & 75.1 & \bf{75.8} & 46.7 & 75.6 & \bf{75.8}\\
    \abr{pl} & 58.2 & \bf{60.2} & 60.1 & 58.5 & 60.2 & \bf{60.4} & 39.4 & 62.4 & \bf{62.5}\\
    \abr{pt} & 79.5 & 79.7 & \bf{79.9} & 79.9 & 81.0 & \bf{81.2} & 63.1 & 81.1 & \bf{81.7}\\
    \abr{ro} & 58.1 & 60.5 & \bf{61.8} & 59.9 & 60.5 & \bf{62.5} & 27.1 & 61.9 & \bf{63.3}\\
    \abr{ru} & 51.7 & 52.1 & \bf{52.1} & 51.7 & 52.1 & \bf{52.1} & 26.6 & 57.1 & \bf{57.9}\\
    \abr{sk} & 38.0 & 39.3 & \bf{40.4} & 38.0 & 39.3 & \bf{41.7} & 13.3 & 41.5 & \bf{42.3}\\
    \abr{sl} & 32.5 & 34.3 & \bf{36.7} & 32.5 & 34.4 & \bf{36.7} & 12.3 & 36.0 & \bf{37.9}\\
    \abr{sq} & 23.5 & 25.1 & \bf{27.3} & 23.5 & 25.1 & \bf{27.3} & 4.4 & 26.5 & \bf{27.3}\\
    \abr{sv} & 58.7 & 59.6 & \bf{60.7} & 60.9 & 61.2 & \bf{62.6} & 35.6 & 63.8 & \bf{63.9}\\
    \abr{ta} & 15.1 & 15.5 & \bf{16.8} & 15.1 & 15.5 & \bf{17.7} & 6.7 & 16.3 & \bf{17.1}\\
    \abr{th} & 22.5 & \bf{23.3} & 22.9 & 22.5 & \bf{23.3} & 22.9 & 9.4 & 23.7 & \bf{23.9}\\
    \abr{tr} & 44.9 & 46.5 & \bf{48.7} & 46.3 & 48.7 & \bf{51.7} & 18.3 & 50.7 & \bf{52.4}\\
    \abr{uk} & 34.8 & 35.9 & \bf{36.3} & 35.5 & 35.9 & \bf{36.5} & 18.8 & 40.7 & \bf{40.8}\\
    \abr{vi} & 41.3 & 42.1 & \bf{43.7} & 42.1 & 42.7 & \bf{44.2} & 14.2 & 43.3 & \bf{43.9}\\
    \abr{zh} & 32.5 & 42.3 & \bf{44.2} & 32.5 & 42.3 & \bf{44.2} & 17.1 & 45.1 & \bf{48.6}\\
    \midrule
    Average & 44.7 & 46.3 & \bf{48.4} & 45.3 & 47.0 & \bf{49.1} & 21.8 & 49.0 & \bf{50.9}\\
    \bottomrule
  \end{tabular}
  \caption{Word translation accuracy aligning English embeddings to thirty-nine
  languages.
  We combine three normalizations---no normalization (None), mean
  centering and length normalization (\abr{c+l}), and \name{}
  (\abr{in}) for five rounds---with three \abr{clwe}s: Procrustes, Procrustes
  with refinement~\citep{conneau-18}, and
  \abr{rcsls}~\citep{joulin-18}.
  Procrustes with \abr{c+l} is equivalent to \citet{artetxe-16}.
  The best result for each \abr{clwe} in each column \textbf{in
  bold}.  \name{} has the best accuracy of the three normalization techniques.}
  \label{tab:result_all}
\end{table*}
