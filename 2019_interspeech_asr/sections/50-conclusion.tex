
\section{Conclusion}
\label{sec:conclusion}

Question answering, like many \textsc{nlp} tasks are impaired by noisy inputs.
Introducing \asr{} into a \abr{qa} pipeline corrupts
the data.  A neural model that uses the \asr{} system's confidence outputs and systematic forced decoding of words rather than unknowns improves  \textsc{qa} accuracy on \qb{} and Jeopardy! questions.  
Our methods are task agnostic and can be applied to other supervised \textsc{nlp} tasks.
Larger human-recorded question datasets and alternate model approaches
would ensure spoken questions are answered accurately, allowing human
and computer trivia players to compete on an equal playing field.





