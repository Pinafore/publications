\begin{abstract}

Natural language processing systems are often downstream of unreliable inputs: machine translation, optical character recognition, or speech recognition.
For instance, virtual assistants can only answer your questions after understanding your speech.
We investigate and mitigate the effects of noise from Automatic Speech Recognition systems on two factoid Question Answering (\textsc{qa}) tasks.
 Integrating confidences into the model and forced decoding of unknown words are empirically shown to improve the accuracy of downstream neural \textsc{qa} systems.  
We create and train models on a synthetic corpus of over 500,000 noisy sentences and evaluate on two human corpora from \qb{} and Jeopardy! competitions.


\end{abstract}
 